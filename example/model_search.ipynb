{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#from modelgym import model\n",
    "import functools\n",
    "import modelgym\n",
    "from modelgym.util import TASK_CLASSIFICATION\n",
    "from modelgym.trainer import Trainer\n",
    "from modelgym.tracker import ProgressTrackerFile, ProgressTrackerMongo\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from hyperopt.mongoexp import MongoTrials\n",
    "from modelgym.util import split_and_preprocess\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using File as backend for tracking\n",
      "Running experiment cofiguration: test\n"
     ]
    }
   ],
   "source": [
    "########### NROWS, N_ESTIMATORS, N_PROBES, TEST_SIZE, N_CV_SPLITS, OPTIMIZER\n",
    "config_tuple = {\n",
    "    'test': (1000, 100,  2, 0.5, 2, 'random'),\n",
    "    'pror': (None, 1000, 100, 0.5, 2, 'random'), # production with random hyperopt suggestor\n",
    "    'prot': (None, 1000, 100, 0.5, 2, 'tpe'),    # production with tpe hyperopt suggestor\n",
    "    'demi': (10000, 100, 5, 0.5, 2, 'random')\n",
    "}\n",
    "CONFIG = 'test' if 'EXP_CONFIG' not in os.environ else os.environ['EXP_CONFIG']\n",
    "NROWS, N_ESTIMATORS, N_PROBES, TEST_SIZE, N_CV_SPLITS, OPTIMIZER = config_tuple[CONFIG]\n",
    "CANDIDATES = OrderedDict([\n",
    "    ('XGBoost', modelgym.XGBModel), \n",
    "    ('LightGBM', modelgym.LGBModel),\n",
    "    ('RandomForestClassifier',modelgym.RFModel)\n",
    "])\n",
    "RESULTS_DIR = \"results\"\n",
    "LOAD_CACHE = False\n",
    "if 'MONGO_PORT_27017_TCP_ADDR' in os.environ:\n",
    "    mongo_host = os.environ['MONGO_PORT_27017_TCP_ADDR'] if 'MONGO_PORT_27017_TCP_ADDR' in os.environ else 'cern-mc01h'\n",
    "    mongo_port = int(os.environ['MONGO_PORT_27017_TCP_PORT']) if 'MONGO_PORT_27017_TCP_PORT' in os.environ else 27017\n",
    "    mongo_db = os.environ['MONGO_DB'] if 'MONGO_DB' in os.environ else 'trials'\n",
    "    tracker_factory = functools.partial(ProgressTrackerMongo, mongo_host, mongo_port, mongo_db, config_key=CONFIG)\n",
    "    print (\"Using Mongo as backend for tracking\")\n",
    "else:\n",
    "    tracker_factory = functools.partial(ProgressTrackerFile, RESULTS_DIR, config_key=CONFIG)\n",
    "    print (\"Using File as backend for tracking\")\n",
    "\n",
    "print (\"Running experiment cofiguration:\", CONFIG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download & read data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 266224\n",
      "-rw-r--r--  1 macbook  staff  136304022 Aug 11 14:40 XY2d.pickle\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "if [ ! -d data ] ; then \n",
    "    mkdir data \n",
    "    cd data\n",
    "    curl https://cernbox.cern.ch/index.php/s/N1dpSAPgl30szYM/download | gunzip -c > XY2d.pickle\n",
    "    cd ..\n",
    "fi\n",
    "ls -l data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_data(fname, nrows=None, shuffle=True):\n",
    "    with open(fname,'rb') as fh:\n",
    "        X, y = pickle.load(fh,encoding='bytes')\n",
    "    index = np.arange(X.shape[0])\n",
    "    if nrows is None:\n",
    "        nrows = X.shape[0]\n",
    "    weights = np.ones(nrows) # uh, well...\n",
    "    if shuffle:\n",
    "        index_perm = np.random.permutation(index)\n",
    "    else:\n",
    "        index_perm = index\n",
    "    return X[index_perm[:nrows]], y[index_perm[:nrows]], weights\n",
    "\n",
    "\n",
    "X, y, weights = read_data(\"data/XY2d.pickle\", nrows=NROWS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, w_train, w_test = train_test_split(X, y, weights, test_size=TEST_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv_pairs, (dtrain, dtest) = split_and_preprocess(X_train.copy(), y_train, \n",
    "                                                X_test.copy(), y_test, \n",
    "                                                cat_cols=[], n_splits=N_CV_SPLITS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run them all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trackers = {}\n",
    "def init_keys_dict():\n",
    "    return dict([(k, None) for k in CANDIDATES.keys()])\n",
    "default_cv_result = init_keys_dict()\n",
    "tuned_cv_result = init_keys_dict()\n",
    "default_test_result = init_keys_dict()\n",
    "tuned_test_result = init_keys_dict()\n",
    "trials = init_keys_dict()\n",
    "trainer = Trainer(hyperopt_evals=N_PROBES, n_estimators=N_ESTIMATORS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~~ XGBoost ~~~~~~~~~~~~~~~~~~~~\n",
      "BST  <xgboost.core.Booster object at 0x1159fc6d8>\n",
      "RES [0.63879, 0.594076, 0.555677, 0.528966, 0.503484, 0.483325, 0.463834, 0.448553, 0.435343, 0.424926, 0.414957, 0.407857, 0.400873, 0.394292, 0.387076, 0.383874, 0.38081, 0.372378, 0.367894, 0.363748, 0.362701, 0.36271, 0.361124, 0.357371, 0.352849, 0.351781, 0.352419, 0.34834, 0.348148, 0.347298, 0.346438, 0.343527, 0.343406, 0.337836, 0.336972, 0.334423, 0.336547, 0.338204, 0.336691, 0.337057, 0.339666, 0.335501, 0.334719, 0.333408, 0.33419, 0.334643, 0.335052, 0.334504, 0.33321, 0.333896, 0.334879, 0.334047, 0.333691, 0.333594, 0.331351, 0.332904, 0.332131, 0.332774, 0.333414, 0.333466, 0.333126, 0.33299, 0.333708, 0.331236, 0.333603, 0.33439, 0.334471, 0.335698, 0.33436, 0.336219, 0.336308, 0.337511, 0.338087, 0.339563, 0.338635, 0.339184, 0.339584, 0.340892, 0.342912, 0.344065, 0.344881, 0.346565, 0.346565, 0.348872, 0.349709, 0.348517, 0.349556, 0.350273, 0.350932, 0.349453, 0.349837, 0.352077, 0.352268, 0.353831, 0.354949, 0.354162, 0.354885, 0.356133, 0.355304, 0.356138]\n",
      "BST  <xgboost.core.Booster object at 0x1159fc6a0>\n",
      "RES [0.642905, 0.601701, 0.569137, 0.537866, 0.511897, 0.492203, 0.475591, 0.458951, 0.447334, 0.435529, 0.425013, 0.418712, 0.408601, 0.40236, 0.39519, 0.391445, 0.38877, 0.386497, 0.37575, 0.371476, 0.36784, 0.363483, 0.36105, 0.357848, 0.357081, 0.357088, 0.355016, 0.355455, 0.354456, 0.352998, 0.354323, 0.353903, 0.351979, 0.353096, 0.355093, 0.354004, 0.35563, 0.355004, 0.354839, 0.355471, 0.357744, 0.358779, 0.361418, 0.36346, 0.364023, 0.363727, 0.361993, 0.363279, 0.361421, 0.362461, 0.362572, 0.363881, 0.364698, 0.365255, 0.365159, 0.365257, 0.365641, 0.365234, 0.365138, 0.365316, 0.366503, 0.365516, 0.365969, 0.365074, 0.365454, 0.365121, 0.365629, 0.365753, 0.36607, 0.367449, 0.367978, 0.368856, 0.368181, 0.368764, 0.369527, 0.37013, 0.370409, 0.369182, 0.369941, 0.370693, 0.371479, 0.373015, 0.373215, 0.373815, 0.375302, 0.375548, 0.375528, 0.37547, 0.375232, 0.37636, 0.377528, 0.376469, 0.376469, 0.377837, 0.378322, 0.378224, 0.37981, 0.3787, 0.378027, 0.378251]\n",
      "saved state to results/tracker_test_XGBoost.pickle\n",
      "Default XGBoost result on CV:\n",
      "\n",
      "loss = 0.3442135\n",
      "best_n_estimators = 36\n",
      "params = {'base_score': 0.5, 'colsample_bylevel': 1, 'colsample_bytree': 1, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 3, 'min_child_weight': 1, 'missing': None, 'n_estimators': 100, 'nthread': -1, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': 0, 'subsample': 1, 'objective': 'binary:logistic', 'eval_metric': 'logloss', 'silent': 1}\n",
      "BST  <xgboost.core.Booster object at 0x1159fc8d0>\n",
      "RES [0.642234, 0.600895, 0.567785, 0.540902, 0.51632, 0.497368, 0.482103, 0.466685, 0.454488, 0.444439, 0.434941, 0.427046, 0.421092, 0.416029, 0.412625, 0.408025, 0.404655, 0.401207, 0.397808, 0.395386, 0.393221, 0.390568, 0.388216, 0.38734, 0.385586, 0.382632, 0.379142, 0.377496, 0.375003, 0.374827, 0.373667, 0.372191, 0.370832, 0.371232, 0.371598, 0.370804]\n",
      "saved state to results/tracker_test_XGBoost.pickle\n",
      "Default XGBoost result on TEST:\n",
      "\n",
      "loss = 0.370804\n",
      "n_estimators = 36\n",
      "params = {'base_score': 0.5, 'colsample_bylevel': 1, 'colsample_bytree': 1, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 3, 'min_child_weight': 1, 'missing': None, 'n_estimators': 100, 'nthread': -1, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': 0, 'subsample': 1, 'objective': 'binary:logistic', 'eval_metric': 'logloss', 'silent': 1}\n",
      "roc_auc = 0.796446\n",
      "Hyperopt iterations:\n",
      "\n",
      "\n",
      "BST  <xgboost.core.Booster object at 0x1159eb940>\n",
      "RES [0.59658, 0.536835, 0.486212, 0.459164, 0.42891, 0.415649, 0.404334, 0.393573, 0.389638, 0.390326, 0.39689, 0.394413, 0.386528, 0.382999, 0.388831, 0.398965, 0.409078, 0.42552, 0.434957, 0.442089, 0.45247, 0.467624, 0.470262, 0.474163, 0.47061, 0.477617, 0.482729, 0.479066, 0.482123, 0.482496, 0.480056, 0.482725, 0.483819, 0.489057, 0.494663, 0.500135, 0.499619, 0.500845, 0.500035, 0.506105, 0.501791, 0.499676, 0.499784, 0.496829, 0.498378, 0.499105, 0.502402, 0.506235, 0.504512, 0.510482, 0.516272, 0.515805, 0.526058, 0.537962, 0.541076, 0.545534, 0.54048, 0.541014, 0.54108, 0.540951, 0.540305, 0.543348, 0.541045, 0.541705, 0.550875, 0.549736, 0.549851, 0.550148, 0.545872, 0.550829, 0.550923, 0.551477, 0.553944, 0.556121, 0.557274, 0.556886, 0.55638, 0.56116, 0.559639, 0.558266, 0.557905, 0.55901, 0.560555, 0.564414, 0.563921, 0.567278, 0.563897, 0.564802, 0.564543, 0.56734, 0.56377, 0.56214, 0.56094, 0.56056, 0.561285, 0.564404, 0.564998, 0.566817, 0.571452, 0.574874]\n",
      "BST  <xgboost.core.Booster object at 0x128be4160>\n",
      "RES [0.596743, 0.527412, 0.494718, 0.462212, 0.446777, 0.419568, 0.409247, 0.394279, 0.390695, 0.380824, 0.383764, 0.383612, 0.376578, 0.379854, 0.386255, 0.389316, 0.390193, 0.394556, 0.395993, 0.402553, 0.40939, 0.41814, 0.419556, 0.427793, 0.436748, 0.439934, 0.440446, 0.442331, 0.444521, 0.444141, 0.445655, 0.443677, 0.446493, 0.443387, 0.444359, 0.442962, 0.444112, 0.45234, 0.446518, 0.450987, 0.456819, 0.451832, 0.450711, 0.453019, 0.455145, 0.457153, 0.458084, 0.465187, 0.464384, 0.466945, 0.462792, 0.457059, 0.45872, 0.462567, 0.463145, 0.459867, 0.463777, 0.464665, 0.467544, 0.462276, 0.462578, 0.460449, 0.462514, 0.459041, 0.461864, 0.464577, 0.464081, 0.460152, 0.464031, 0.473326, 0.476879, 0.480211, 0.482727, 0.480756, 0.479563, 0.474936, 0.474564, 0.472892, 0.477546, 0.48221, 0.484982, 0.483534, 0.486352, 0.484469, 0.483526, 0.484357, 0.483855, 0.481966, 0.481862, 0.482447, 0.4858, 0.488046, 0.485149, 0.48458, 0.480351, 0.484268, 0.485127, 0.484444, 0.485909, 0.48823]\n",
      "[1/2]\teval_time=0.17 sec\tcurrent_logloss=0.381427\tmin_logloss=0.381427\n",
      "BST  <xgboost.core.Booster object at 0x1159eb940>\n",
      "RES [0.48346, 0.415417, 0.397556, 0.397055, 0.397355, 0.417677, 0.421293, 0.416838, 0.423495, 0.443092, 0.457625, 0.458322, 0.474733, 0.494288, 0.50978, 0.524569, 0.549222, 0.569633, 0.592902, 0.6214, 0.636685, 0.653724, 0.674229, 0.684454, 0.678219, 0.696222, 0.717511, 0.740137, 0.753224, 0.765797, 0.786074, 0.786236, 0.793604, 0.801739, 0.803191, 0.812111, 0.805437, 0.819522, 0.810908, 0.809917, 0.807615, 0.821419, 0.818419, 0.826115, 0.831234, 0.825805, 0.8258, 0.823421, 0.822095, 0.821513, 0.82205, 0.82102, 0.820867, 0.820836, 0.823498, 0.823392, 0.823246, 0.823118, 0.820644, 0.821218, 0.820674, 0.822036, 0.824717, 0.823771, 0.819685, 0.81971, 0.822082, 0.82139, 0.81924, 0.820868, 0.817462, 0.821764, 0.823844, 0.82731, 0.831422, 0.827021, 0.824033, 0.818617, 0.818449, 0.822364, 0.820847, 0.822507, 0.821402, 0.818924, 0.823176, 0.821665, 0.818435, 0.817111, 0.823203, 0.821118, 0.823128, 0.826603, 0.82699, 0.829818, 0.826922, 0.825487, 0.825226, 0.825211, 0.828784, 0.826586]\n",
      "BST  <xgboost.core.Booster object at 0x1159fc940>\n",
      "RES [0.532201, 0.457976, 0.413584, 0.40397, 0.397587, 0.407732, 0.412471, 0.406962, 0.419483, 0.418959, 0.443258, 0.445229, 0.455076, 0.469158, 0.494949, 0.50938, 0.51759, 0.531659, 0.543179, 0.562962, 0.590716, 0.608053, 0.638498, 0.666956, 0.677967, 0.683705, 0.716535, 0.734455, 0.747578, 0.744894, 0.742966, 0.753257, 0.762133, 0.765721, 0.795523, 0.818716, 0.837605, 0.857077, 0.865951, 0.874692, 0.869437, 0.857688, 0.858416, 0.854082, 0.881664, 0.887058, 0.882998, 0.884695, 0.883688, 0.889277, 0.898528, 0.895281, 0.894251, 0.8948, 0.902911, 0.904708, 0.90205, 0.897537, 0.8969, 0.900892, 0.899964, 0.897336, 0.91629, 0.917739, 0.91825, 0.92144, 0.922255, 0.92198, 0.92281, 0.922979, 0.921322, 0.921261, 0.921099, 0.920202, 0.922283, 0.918303, 0.921005, 0.915612, 0.917233, 0.91908, 0.916985, 0.916671, 0.921466, 0.917797, 0.920094, 0.920238, 0.915347, 0.915979, 0.914028, 0.91631, 0.921044, 0.924478, 0.925478, 0.923431, 0.91922, 0.918227, 0.917662, 0.912221, 0.916628, 0.916422]\n",
      "[2/2]\teval_time=0.18 sec\tcurrent_logloss=0.397471\tmin_logloss=0.381427\n",
      "saved state to results/tracker_test_XGBoost.pickle\n",
      "saved state to results/tracker_test_XGBoost.pickle\n",
      "Tuned XGBoost result on cv:\n",
      "\n",
      "loss = 0.3814265\n",
      "best_n_estimators = 14\n",
      "params = {'alpha': 0, 'colsample_bylevel': 0.7405046763756069, 'colsample_bytree': 0.6151399892026908, 'eta': 0.22398969443165967, 'gamma': 5.745168482871384e-07, 'lambda': 0.019440307789833522, 'max_depth': 10, 'min_child_weight': 0.16853765259109013, 'subsample': 0.6197753137030573, 'objective': 'binary:logistic', 'eval_metric': 'logloss', 'silent': 1}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BST  <xgboost.core.Booster object at 0x1159fc860>\n",
      "RES [0.581495, 0.515429, 0.473935, 0.442495, 0.415819, 0.395727, 0.379557, 0.374789, 0.368373, 0.36314, 0.359892, 0.363029, 0.364177, 0.36978]\n",
      "saved state to results/tracker_test_XGBoost.pickle\n",
      "Tuned XGBoost result on test:\n",
      "\n",
      "loss = 0.36978\n",
      "n_estimators = 14\n",
      "params = {'alpha': 0, 'colsample_bylevel': 0.7405046763756069, 'colsample_bytree': 0.6151399892026908, 'eta': 0.22398969443165967, 'gamma': 5.745168482871384e-07, 'lambda': 0.019440307789833522, 'max_depth': 10, 'min_child_weight': 0.16853765259109013, 'subsample': 0.6197753137030573, 'objective': 'binary:logistic', 'eval_metric': 'logloss', 'silent': 1}\n",
      "roc_auc = 0.822144\n",
      "saved state to results/tracker_test_XGBoost.pickle\n",
      "~~~~~~~~~~~~~~~~~~~~ LightGBM ~~~~~~~~~~~~~~~~~~~~\n",
      "saved state to results/tracker_test_LightGBM.pickle\n",
      "Default LightGBM result on CV:\n",
      "\n",
      "loss = 0.353675349257\n",
      "best_n_estimators = 28\n",
      "params = {'boosting_type': 'gbdt', 'colsample_bytree': 1, 'drop_rate': 0.1, 'is_unbalance': False, 'learning_rate': 0.1, 'max_bin': 255, 'min_data_in_leaf': 20, 'max_depth': -1, 'max_drop': 50, 'min_child_samples': 10, 'min_child_weight': 5, 'min_split_gain': 0, 'min_sum_hessian_in_leaf': 0.001, 'lambda_l1': 0, 'lambda_l2': 0, 'n_estimators': 10, 'nthread': 4, 'num_threads': 4, 'num_leaves': 31, 'reg_alpha': 0, 'reg_lambda': 0, 'scale_pos_weight': 1, 'seed': 0, 'sigmoid': 1.0, 'skip_drop': 0.5, 'subsample': 1, 'subsample_for_bin': 50000, 'subsample_freq': 1, 'uniform_drop': False, 'xgboost_dart_mode': False, 'objective': 'binary', 'metric': 'binary_logloss', 'bagging_freq': 1, 'verbose': -1}\n",
      "saved state to results/tracker_test_LightGBM.pickle\n",
      "Default LightGBM result on TEST:\n",
      "\n",
      "loss = 0.382416513966\n",
      "n_estimators = 28\n",
      "params = {'boosting_type': 'gbdt', 'colsample_bytree': 1, 'drop_rate': 0.1, 'is_unbalance': False, 'learning_rate': 0.1, 'max_bin': 255, 'min_data_in_leaf': 20, 'max_depth': -1, 'max_drop': 50, 'min_child_samples': 10, 'min_child_weight': 5, 'min_split_gain': 0, 'min_sum_hessian_in_leaf': 0.001, 'lambda_l1': 0, 'lambda_l2': 0, 'n_estimators': 10, 'nthread': 4, 'num_threads': 4, 'num_leaves': 31, 'reg_alpha': 0, 'reg_lambda': 0, 'scale_pos_weight': 1, 'seed': 0, 'sigmoid': 1.0, 'skip_drop': 0.5, 'subsample': 1, 'subsample_for_bin': 50000, 'subsample_freq': 1, 'uniform_drop': False, 'xgboost_dart_mode': False, 'objective': 'binary', 'metric': 'binary_logloss', 'bagging_freq': 1, 'verbose': -1}\n",
      "roc_auc = 0.778073\n",
      "Hyperopt iterations:\n",
      "\n",
      "\n",
      "[1/2]\teval_time=0.09 sec\tcurrent_logloss=0.693147\tmin_logloss=0.693147\n",
      "[2/2]\teval_time=1.32 sec\tcurrent_logloss=0.585188\tmin_logloss=0.585188\n",
      "saved state to results/tracker_test_LightGBM.pickle\n",
      "saved state to results/tracker_test_LightGBM.pickle\n",
      "Tuned LightGBM result on cv:\n",
      "\n",
      "loss = 0.5851880109642293\n",
      "best_n_estimators = 100\n",
      "params = {'bagging_fraction': 0.5292435929542255, 'feature_fraction': 0.9444627024858503, 'lambda_l1': 0, 'lambda_l2': 0, 'learning_rate': 0.0025275717184566064, 'min_data_in_leaf': 10, 'min_sum_hessian_in_leaf': 4.1073662953607967e-07, 'num_leaves': 137, 'objective': 'binary', 'metric': 'binary_logloss', 'bagging_freq': 1, 'verbose': -1, 'max_bin': 255}\n",
      "saved state to results/tracker_test_LightGBM.pickle\n",
      "Tuned LightGBM result on test:\n",
      "\n",
      "loss = 0.585405775417\n",
      "n_estimators = 100\n",
      "params = {'bagging_fraction': 0.5292435929542255, 'feature_fraction': 0.9444627024858503, 'lambda_l1': 0, 'lambda_l2': 0, 'learning_rate': 0.0025275717184566064, 'min_data_in_leaf': 10, 'min_sum_hessian_in_leaf': 4.1073662953607967e-07, 'num_leaves': 137, 'objective': 'binary', 'metric': 'binary_logloss', 'bagging_freq': 1, 'verbose': -1, 'max_bin': 255}\n",
      "roc_auc = 0.789807\n",
      "saved state to results/tracker_test_LightGBM.pickle\n",
      "~~~~~~~~~~~~~~~~~~~~ RandomForestClassifier ~~~~~~~~~~~~~~~~~~~~\n",
      "XYCDataset(X=array([[   0.        ,  -20.92237473,  143.50805664, ...,    0.        ,\n",
      "           2.41055727,    2.41055727],\n",
      "       [   0.        ,    0.        ,    0.        , ...,    0.        ,\n",
      "           0.        ,    0.        ],\n",
      "       [   0.        ,    0.        ,    0.        , ...,    0.        ,\n",
      "           0.        ,    0.        ],\n",
      "       ..., \n",
      "       [ 408.59780884,  306.4659729 ,  139.53129578, ...,    0.        ,\n",
      "           0.        ,    0.        ],\n",
      "       [  19.08793068,  408.52700806,  174.01701355, ...,    0.        ,\n",
      "           0.        ,    9.37438869],\n",
      "       [   0.        ,    0.        ,    0.        , ...,    0.        ,\n",
      "           0.        ,    0.        ]]), y=array([1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1,\n",
      "       1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0,\n",
      "       1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
      "       1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1]), cat_cols=[])\n",
      "XYCDataset(X=array([[  0.00000000e+00,  -1.99112644e+01,   4.75945702e+01, ...,\n",
      "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
      "       [  4.53133453e+02,   4.08501831e+02,   5.43710693e+02, ...,\n",
      "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
      "       [  0.00000000e+00,   1.69942795e+02,   2.15539398e+02, ...,\n",
      "          4.47292290e+01,   0.00000000e+00,   0.00000000e+00],\n",
      "       ..., \n",
      "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00, ...,\n",
      "          1.33919847e+00,   0.00000000e+00,   0.00000000e+00],\n",
      "       [  0.00000000e+00,   4.50518890e+02,   1.79195691e+03, ...,\n",
      "          0.00000000e+00,   0.00000000e+00,   6.42815256e+00],\n",
      "       [  0.00000000e+00,   7.84312210e+01,   6.55749512e+02, ...,\n",
      "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00]]), y=array([1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0,\n",
      "       0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1,\n",
      "       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1,\n",
      "       0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1,\n",
      "       1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1]), cat_cols=[])\n",
      "{'criterion': 'gini', 'max_depth': 14, 'max_features': 1, 'n_estimators': 10, 'normalize': 0, 'scale': 0}\n",
      "{'max_depth': 1, 'max_features': 4, 'n_estimators': 10, 'criterion': 'gini', 'verbose': 0}\n",
      "[0.83958365401209945, 0.851439439523483, 0.85139162923470879, 0.851439439523483, 0.84359971826912761, 0.84747118555522905, 0.85550448017388947, 0.85545550378051116, 0.84747118555522905, 0.74691448721716147, 0.81538581736936122, 0.77522517479908026, 0.80348688598762064, 0.85139162923470879, 0.851439439523483, 0.827194958696575, 0.7871287705992378, 0.84752016194860735, 0.84350293158697509, 0.83140692852711651, 0.84747118555522905, 0.84345512129820088, 0.83953467761872114, 0.83948686732994693, 0.8435519079803534, 0.85545550378051116, 0.85952054443091763, 0.84737439887307653, 0.83934110425441599, 0.84732658858430232, 0.85153622620563552, 0.81921064047129288, 0.851439439523483, 0.85540769349173695, 0.851439439523483, 0.851439439523483, 0.85947156803753921, 0.84742220916185074, 0.85144060562808732, 0.84742337526645484, 0.85139162923470879, 0.84321373764512175, 0.85144060562808732, 0.851439439523483, 0.851439439523483, 0.83948686732994693, 0.85942375774876512, 0.83939008064779441, 0.84350409769157941, 0.84742337526645484, 0.84742337526645484, 0.851439439523483, 0.85139162923470879, 0.84756797223738156, 0.851439439523483, 0.85158403649440961, 0.83939008064779441, 0.79119264514504017, 0.84335833461604837, 0.83948686732994693, 0.8314057624225123, 0.851439439523483, 0.80672399236901138, 0.85550448017388947, 0.83938891454319009, 0.83943789093656862, 0.851439439523483, 0.85153622620563552, 0.68661638423613158, 0.851439439523483, 0.82351823087938281, 0.85550448017388947, 0.84737323276847221, 0.85129367644795206, 0.83934227035902031, 0.83159816968221312, 0.84737439887307653, 0.84747118555522905, 0.85153622620563552, 0.83135678602913388, 0.84345512129820088, 0.85540652738713263, 0.85961733111307026, 0.85153622620563552, 0.85956952082429605, 0.85153622620563552, 0.85168082317656213, 0.84752016194860735, 0.851439439523483, 0.85550448017388947, 0.83160166799602597, 0.83542182667954046, 0.81945319022897634, 0.85550448017388947, 0.84747235165983337, 0.70718880166426457, 0.85952054443091763, 0.83546963696831467, 0.83939008064779441, 0.84355074187574919, 0.85134265284133048, 0.85163301288778814, 0.84761694863075998, 0.85947273414214342, 0.78310920802839712, 0.85550448017388947, 0.84747118555522905, 0.851439439523483, 0.851439439523483, 0.851439439523483, 0.84330935822266995, 0.84742337526645484, 0.851439439523483, 0.84345512129820088, 0.8556012668560421, 0.81538698347396554, 0.85153622620563552, 0.851439439523483, 0.83943905704117283, 0.83929329396564178, 0.86358558508132421, 0.83939008064779441, 0.851439439523483, 0.84732658858430232, 0.84737439887307653, 0.6823601024306285, 0.83953467761872114, 0.82738853206087992, 0.81533684097598291, 0.85535988320296286, 0.8314535727112865, 0.851439439523483, 0.851439439523483, 0.84335716851144416, 0.84326038182929164, 0.851439439523483, 0.83934110425441599, 0.851439439523483, 0.82346808838140007, 0.84737439887307653, 0.851439439523483, 0.851439439523483, 0.80333995680748549, 0.82327568112169924, 0.66319633936442635, 0.85540769349173695, 0.83939008064779441, 0.85148724981225721, 0.84747118555522905, 0.85550448017388947, 0.84737439887307653, 0.84742337526645484, 0.86353777479255001, 0.83537285028616204, 0.86755267294497385, 0.85937594745999091, 0.85158403649440961, 0.83542182667954046, 0.85143827341887868, 0.84732658858430232, 0.77517853061491027, 0.84335833461604837, 0.8272427689853491, 0.83527606360400952, 0.81141872950571159, 0.851439439523483, 0.851439439523483, 0.851439439523483, 0.83948686732994693, 0.83135561992452967, 0.851439439523483, 0.83943905704117283, 0.851439439523483, 0.83546963696831467, 0.82743867455886255, 0.851439439523483, 0.84732658858430232, 0.82704919562104406, 0.84330935822266995, 0.66668299213112625, 0.85129367644795206, 0.83125999934698136, 0.79878865053710779, 0.851439439523483, 0.84340614490482257, 0.851439439523483, 0.851439439523483, 0.85956952082429605, 0.87161887969998464, 0.84345512129820088, 0.84345395519359656, 0.84737439887307653, 0.84742220916185074, 0.84747118555522905, 0.84747118555522905, 0.83522825331523531, 0.85148724981225721, 0.851439439523483, 0.84340614490482257, 0.83125999934698136, 0.85560010075143778, 0.8071624477002084, 0.75088274118541543, 0.82738969816548424, 0.85956952082429605, 0.83547080307291877, 0.82748648484763676, 0.851439439523483, 0.851439439523483, 0.73462491079299763, 0.85550448017388947, 0.851439439523483, 0.851439439523483, 0.85550448017388947, 0.75117310123187286, 0.86765062573173068, 0.83546963696831467, 0.83130780963575557, 0.84340614490482257, 0.84335833461604837, 0.81949983441314611, 0.83140459631790808, 0.64645340945664198, 0.84742337526645484, 0.85966630750644857, 0.81925728465546277, 0.85138929702550037, 0.79937053673462721, 0.8556012668560421, 0.8556012668560421, 0.83125999934698136, 0.81122748835061487, 0.851439439523483, 0.84751899584400314, 0.851439439523483, 0.84752016194860735, 0.83537401639076636, 0.851439439523483, 0.851439439523483, 0.84330935822266995, 0.84766475891953419, 0.83943789093656862, 0.7189956107822697, 0.83532503999738783, 0.851439439523483, 0.83546963696831467, 0.83537285028616204, 0.83542182667954046, 0.76317231760957893, 0.84747118555522905, 0.84737439887307653, 0.851439439523483, 0.85971411779522267, 0.84742220916185074, 0.851439439523483, 0.851439439523483, 0.86358558508132421, 0.83537285028616204, 0.84340614490482257, 0.83958365401209945, 0.84737556497768074, 0.83948686732994693, 0.84747118555522905, 0.85535871709835865, 0.83948686732994693, 0.85158520259901394, 0.84742337526645484, 0.83121102295360316, 0.851439439523483, 0.83938891454319009, 0.82318006054415094, 0.79109585846288744, 0.84752016194860735, 0.72296153254131512, 0.85148724981225721, 0.85153739231023984, 0.84340614490482257, 0.84359971826912761, 0.8314057624225123, 0.81103041667249709, 0.851439439523483, 0.85545550378051116, 0.80740383135328775, 0.84737439887307653, 0.851439439523483, 0.851439439523483, 0.84326038182929164, 0.84350293158697509, 0.8193552374422195, 0.85550448017388947, 0.84747118555522905, 0.851439439523483, 0.83972825098302606, 0.851439439523483, 0.83938891454319009, 0.84756797223738156, 0.73888352480770936, 0.85550448017388947, 0.8435985521645234, 0.84756913834198588]\n",
      "XYCDataset(X=array([[  0.00000000e+00,  -1.99112644e+01,   4.75945702e+01, ...,\n",
      "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
      "       [  4.53133453e+02,   4.08501831e+02,   5.43710693e+02, ...,\n",
      "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
      "       [  0.00000000e+00,   1.69942795e+02,   2.15539398e+02, ...,\n",
      "          4.47292290e+01,   0.00000000e+00,   0.00000000e+00],\n",
      "       ..., \n",
      "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00, ...,\n",
      "          1.33919847e+00,   0.00000000e+00,   0.00000000e+00],\n",
      "       [  0.00000000e+00,   4.50518890e+02,   1.79195691e+03, ...,\n",
      "          0.00000000e+00,   0.00000000e+00,   6.42815256e+00],\n",
      "       [  0.00000000e+00,   7.84312210e+01,   6.55749512e+02, ...,\n",
      "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00]]), y=array([1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0,\n",
      "       0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1,\n",
      "       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1,\n",
      "       0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1,\n",
      "       1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1]), cat_cols=[])\n",
      "XYCDataset(X=array([[   0.        ,  -20.92237473,  143.50805664, ...,    0.        ,\n",
      "           2.41055727,    2.41055727],\n",
      "       [   0.        ,    0.        ,    0.        , ...,    0.        ,\n",
      "           0.        ,    0.        ],\n",
      "       [   0.        ,    0.        ,    0.        , ...,    0.        ,\n",
      "           0.        ,    0.        ],\n",
      "       ..., \n",
      "       [ 408.59780884,  306.4659729 ,  139.53129578, ...,    0.        ,\n",
      "           0.        ,    0.        ],\n",
      "       [  19.08793068,  408.52700806,  174.01701355, ...,    0.        ,\n",
      "           0.        ,    9.37438869],\n",
      "       [   0.        ,    0.        ,    0.        , ...,    0.        ,\n",
      "           0.        ,    0.        ]]), y=array([1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1,\n",
      "       1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0,\n",
      "       1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
      "       1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1]), cat_cols=[])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'gini', 'max_depth': 5, 'max_features': 3, 'n_estimators': 16, 'normalize': 0, 'scale': 1}\n",
      "{'max_depth': 1, 'max_features': 4, 'n_estimators': 10, 'criterion': 'gini', 'verbose': 0}\n",
      "[0.85264868999808752, 0.74909160451329126, 0.84064830751577746, 0.84461656148403141, 0.78490151080512527, 0.82066360680818506, 0.84863262574105958, 0.79699751386498363, 0.84466437177280562, 0.85260087970931353, 0.78514056224899598, 0.8087588449034232, 0.78509275196022177, 0.84863262574105958, 0.84863262574105958, 0.80885446548097162, 0.83280742015681775, 0.84863262574105958, 0.85260087970931353, 0.84863262574105958, 0.84863262574105958, 0.84863262574105958, 0.67742398164084905, 0.80474278064639515, 0.84475999235035371, 0.8287435456110156, 0.84466437177280562, 0.84064830751577746, 0.84471218206157961, 0.80488621151271766, 0.84863262574105958, 0.84069611780455167, 0.8366322432587493, 0.84863262574105958, 0.83668005354752351, 0.82095046854082998, 0.84069611780455145, 0.85666475425511568, 0.84466437177280562, 0.84863262574105958, 0.85260087970931353, 0.84877605660738187, 0.85661694396634147, 0.80483840122394346, 0.81277490916045136, 0.85269650028686172, 0.80474278064639515, 0.78886976477337933, 0.81291834002677366, 0.83275960986804354, 0.63745458022566448, 0.84863262574105958, 0.80890227576974583, 0.8366322432587493, 0.84863262574105958, 0.79279020845285908, 0.84863262574105958, 0.85264868999808752, 0.80082233696691529, 0.84863262574105958, 0.85269650028686172, 0.84466437177280562, 0.84074392809332565, 0.81683878370625373, 0.84863262574105958, 0.83275960986804354, 0.83672786383629749, 0.84074392809332565, 0.80483840122394346, 0.83275960986804354, 0.67355134825014351, 0.84872824631860777, 0.80091795754446349, 0.73312296806272703, 0.77299674890036341, 0.85269650028686172, 0.84863262574105958, 0.84863262574105958, 0.84868043602983356, 0.85264868999808752, 0.83658443296997509, 0.84868043602983356, 0.83668005354752351, 0.84863262574105958, 0.78112449799196781, 0.84074392809332565, 0.84868043602983356, 0.84868043602983356, 0.82477529164276164, 0.84471218206157961, 0.84466437177280562, 0.82883916618856379, 0.83275960986804354, 0.85274431057563582, 0.83668005354752351, 0.81291834002677377, 0.84466437177280562, 0.84064830751577746, 0.82477529164276164, 0.7807420156817747, 0.69736087205966724, 0.84863262574105958, 0.84863262574105958, 0.84069611780455167, 0.77304455918913761, 0.79694970357620953, 0.82482310193153563, 0.85661694396634147, 0.84069611780455167, 0.84863262574105958, 0.84868043602983356, 0.8287435456110156, 0.84064830751577746, 0.85269650028686172, 0.84069611780455145, 0.8287435456110156, 0.78102887741441951, 0.8446643717728054, 0.84863262574105958, 0.84074392809332565, 0.84069611780455145, 0.85656913367756748, 0.84060049722700325, 0.73713903231975531, 0.84863262574105958, 0.79685408299866134, 0.84074392809332565, 0.83271179957926955, 0.84466437177280562, 0.7807898259705488, 0.84466437177280562, 0.84863262574105958, 0.84069611780455145, 0.83275960986804354, 0.84466437177280562, 0.84863262574105958, 0.84069611780455145, 0.84471218206157961, 0.84466437177280562, 0.84060049722700325, 0.80483840122394346, 0.84064830751577746, 0.82463186077643913, 0.82883916618856379, 0.85666475425511568, 0.83271179957926955, 0.83271179957926955, 0.81674316312870532, 0.80488621151271766, 0.85264868999808752, 0.84863262574105958, 0.79293363931918159, 0.84863262574105958, 0.84863262574105958, 0.83275960986804354, 0.85661694396634147, 0.84863262574105958, 0.8287435456110156, 0.84863262574105958, 0.84466437177280562, 0.84466437177280562, 0.84863262574105958, 0.81683878370625373, 0.83668005354752351, 0.83691910499139421, 0.84074392809332565, 0.84074392809332565, 0.84074392809332565, 0.83672786383629749, 0.78093325683687131, 0.84069611780455145, 0.85671256454388978, 0.82482310193153563, 0.84069611780455145, 0.84466437177280562, 0.84461656148403141, 0.84466437177280562, 0.84863262574105958, 0.85661694396634147, 0.70113788487282458, 0.79690189328743555, 0.82075922738573348, 0.80067890610059289, 0.84863262574105958, 0.85264868999808752, 0.84863262574105958, 0.82487091222030984, 0.82879135589978958, 0.82080703767450769, 0.84466437177280562, 0.84863262574105958, 0.83275960986804354, 0.8287435456110156, 0.83672786383629749, 0.8366322432587493, 0.82472748135398743, 0.84863262574105958, 0.84863262574105958, 0.84466437177280562, 0.82066360680818506, 0.82472748135398743, 0.85260087970931353, 0.85260087970931353, 0.82075922738573348, 0.84863262574105958, 0.84863262574105958, 0.83275960986804354, 0.85656913367756748, 0.82869573532224139, 0.83275960986804354, 0.68904188181296622, 0.84863262574105958, 0.82075922738573348, 0.84471218206157961, 0.86063300822336963, 0.84863262574105958, 0.84863262574105958, 0.8287435456110156, 0.84069611780455167, 0.84069611780455145, 0.84466437177280562, 0.84069611780455167, 0.83672786383629749, 0.84471218206157961, 0.80880665519219741, 0.84471218206157961, 0.81683878370625373, 0.8287435456110156, 0.82085484796328168, 0.85260087970931353, 0.84064830751577746, 0.84461656148403141, 0.85260087970931353, 0.84069611780455167, 0.84863262574105958, 0.68134442532032902, 0.75702811244979917, 0.84461656148403141, 0.84466437177280562, 0.84461656148403141, 0.83668005354752351, 0.84868043602983356, 0.81287052973799978, 0.85260087970931353, 0.84466437177280562, 0.79298144960795558, 0.83668005354752351, 0.82477529164276164, 0.82071141709695927, 0.8366322432587493, 0.8287435456110156, 0.79680627270988724, 0.85264868999808752, 0.6736947791164658, 0.84069611780455167, 0.82075922738573348, 0.84461656148403141, 0.84461656148403141, 0.84863262574105958, 0.84064830751577746, 0.84074392809332565, 0.84069611780455145, 0.84466437177280562, 0.84863262574105958, 0.83672786383629749, 0.84074392809332565, 0.84069611780455145, 0.84466437177280562, 0.84466437177280562, 0.8008701472556895, 0.81679097341747953, 0.83672786383629749, 0.84466437177280562, 0.84466437177280562, 0.83672786383629749, 0.82458405048766492, 0.82467967106521323, 0.84471218206157961, 0.83275960986804354, 0.82477529164276164, 0.77696500286861736, 0.83672786383629749, 0.83266398929049534, 0.8366322432587493, 0.82453624019889082, 0.83266398929049534, 0.81272709887167716, 0.84868043602983356, 0.84863262574105958, 0.84863262574105958, 0.84471218206157961, 0.82487091222030984, 0.84863262574105958, 0.84461656148403141, 0.70118569516159879, 0.84069611780455167, 0.82879135589978958, 0.77323580034423411, 0.84863262574105958, 0.83256836871294704]\n",
      "saved state to results/tracker_test_RandomForestClassifier.pickle\n",
      "Default RandomForestClassifier result on CV:\n",
      "\n",
      "loss = 0.683910438502\n",
      "best_n_estimators = 180\n",
      "params = {'max_depth': 1, 'max_features': 4, 'n_estimators': 10, 'criterion': 'gini', 'verbose': 0}\n",
      "XYCDataset(X=array([[    0.        ,   -20.92237473,   143.50805664, ...,\n",
      "            0.        ,     2.41055727,     2.41055727],\n",
      "       [    0.        ,   -19.91126442,    47.59457016, ...,\n",
      "            0.        ,     0.        ,     0.        ],\n",
      "       [    0.        ,     0.        ,     0.        , ...,\n",
      "            0.        ,     0.        ,     0.        ],\n",
      "       ..., \n",
      "       [    0.        ,   450.51889038,  1791.95690918, ...,\n",
      "            0.        ,     0.        ,     6.42815256],\n",
      "       [    0.        ,     0.        ,     0.        , ...,\n",
      "            0.        ,     0.        ,     0.        ],\n",
      "       [    0.        ,    78.43122101,   655.74951172, ...,\n",
      "            0.        ,     0.        ,     0.        ]]), y=array([1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
      "       0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1,\n",
      "       1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
      "       1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
      "       1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
      "       0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1,\n",
      "       0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1]), cat_cols=[])\n",
      "XYCDataset(X=array([[  0.00000000e+00,   0.00000000e+00,   0.00000000e+00, ...,\n",
      "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
      "       [  1.84412949e+02,   4.75485992e+02,   3.58238159e+02, ...,\n",
      "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
      "       [  6.24764038e+02,   7.41499817e+02,   5.89000671e+02, ...,\n",
      "          0.00000000e+00,   1.87487781e+00,   0.00000000e+00],\n",
      "       ..., \n",
      "       [  2.55986841e+03,   1.76034760e+02,   3.56312286e+02, ...,\n",
      "          4.55327463e+00,   0.00000000e+00,   0.00000000e+00],\n",
      "       [  8.87419617e+02,   4.77270721e+02,   4.49053894e+02, ...,\n",
      "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
      "       [  2.37582748e+02,   1.97217808e+01,   3.69875488e+02, ...,\n",
      "          0.00000000e+00,   0.00000000e+00,   2.14271760e+00]]), y=array([1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
      "       1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1,\n",
      "       1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0,\n",
      "       1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
      "       1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1,\n",
      "       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1,\n",
      "       0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1,\n",
      "       1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
      "       1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
      "       0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1]), cat_cols=[])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'entropy', 'max_depth': 12, 'max_features': 4, 'n_estimators': 5, 'normalize': 1, 'scale': 0}\n",
      "{'max_depth': 1, 'max_features': 4, 'n_estimators': 10, 'criterion': 'gini', 'verbose': 0}\n",
      "[0.84601880576196997, 0.85200682971406583, 0.84999879758555175, 0.84999879758555175, 0.74805810066613754, 0.84801481374600185, 0.84603082990645218, 0.83599066926388188, 0.84003078180987423, 0.83997066108746365, 0.84999879758555175, 0.84999879758555175, 0.81799052497414815, 0.85403891013154409, 0.84797874131255568, 0.85599884568212969, 0.70802972368515993, 0.84003078180987423, 0.81605463771252673, 0.84601880576196997, 0.85599884568212969, 0.85803092609960796, 0.84601880576196997, 0.84998677344106977, 0.85801890195512598, 0.8459947574730059, 0.8220065892311762, 0.85599884568212969, 0.84999879758555175, 0.83603876584181036, 0.84999879758555175, 0.84603082990645218, 0.85203087800303001, 0.84997474929658756, 0.84600678161748799, 0.84203881393838831, 0.83600269340836386, 0.82807878219464692, 0.84200274150494181, 0.84999879758555175, 0.84999879758555175, 0.84999879758555175, 0.85200682971406583, 0.84999879758555175, 0.84203881393838831, 0.84403482192242019, 0.83603876584181036, 0.85799485366616157, 0.84999879758555175, 0.83405478200226046, 0.82803068561671844, 0.73609407690642803, 0.84999879758555175, 0.82798258903878985, 0.84801481374600185, 0.84800278960151987, 0.81802659740759454, 0.84999879758555175, 0.84802683789048405, 0.83403073371329628, 0.85198278142510164, 0.84600678161748799, 0.84403482192242019, 0.83801072553687794, 0.83394656470192141, 0.85199480556958374, 0.844010773633456, 0.85800687781064378, 0.84998677344106977, 0.85603491811557608, 0.77406632518096341, 0.84999879758555175, 0.85400283769809782, 0.86398287761825754, 0.86003895822812204, 0.84801481374600185, 0.84598273332852381, 0.86201091792318973, 0.76205420484332542, 0.84800278960151987, 0.84398672534449182, 0.85599884568212969, 0.86803501430873187, 0.84599475747300579, 0.83801072553687794, 0.83404275785777848, 0.85199480556958374, 0.83597864511939968, 0.83400668542433198, 0.84196666907149564, 0.84603082990645218, 0.84999879758555175, 0.84999879758555175, 0.85001082173003395, 0.84200274150494181, 0.82605872592165064, 0.85199480556958374, 0.84999879758555175, 0.76806627708438546, 0.84600678161748799, 0.73006998052088579, 0.84999879758555175, 0.84600678161748799, 0.85199480556958374, 0.85001082173003395, 0.82996657287833964, 0.844010773633456, 0.84999879758555175, 0.84999879758555175, 0.84999879758555175, 0.84802683789048405, 0.84999879758555175, 0.8339826371353678, 0.82593848447682949, 0.84800278960151987, 0.8459947574730059, 0.81203857345549857, 0.85400283769809782, 0.84603082990645218, 0.84999879758555175, 0.85197075728061955, 0.76995406776807818, 0.85004689416348034, 0.86000288579467565, 0.85602289397109399, 0.84999879758555175, 0.85199480556958374, 0.82601062934372216, 0.84001875766539202, 0.84999879758555175, 0.84999879758555175, 0.84600678161748799, 0.81998653295818003, 0.84601880576196997, 0.84401077363345589, 0.84999879758555175, 0.78205035711709103, 0.82795854074982567, 0.83999470937642773, 0.85001082173003395, 0.85801890195512598, 0.84999879758555175, 0.85399081355361561, 0.84000673352090993, 0.77796214799317032, 0.8459947574730059, 0.84201476564942401, 0.85001082173003395, 0.85400283769809782, 0.84801481374600185, 0.85602289397109399, 0.85603491811557608, 0.83000264531178614, 0.85400283769809782, 0.85403891013154409, 0.83802274968136015, 0.84604285405093427, 0.82001058124714421, 0.84999879758555175, 0.84800278960151987, 0.84801481374600185, 0.84999879758555175, 0.84401077363345589, 0.84600678161748799, 0.83003871774523252, 0.85598682153764749, 0.82400259721520808, 0.83799870139239585, 0.84201476564942401, 0.84600678161748799, 0.84999879758555175, 0.84800278960151987, 0.75993795541447218, 0.85002284587451593, 0.84999879758555175, 0.85402688598706211, 0.84800278960151987, 0.82203063752014049, 0.84001875766539202, 0.84800278960151987, 0.84800278960151987, 0.86001490993915786, 0.83803477382584235, 0.78594617992929805, 0.84800278960151987, 0.79201837289276877, 0.85200682971406583, 0.84999879758555175, 0.84803886203496626, 0.85200682971406583, 0.81404660558401265, 0.84999879758555175, 0.84603082990645218, 0.83799870139239585, 0.85200682971406583, 0.85001082173003384, 0.85203087800303001, 0.80007454969578917, 0.84803886203496626, 0.83999470937642784, 0.84199071736045983, 0.8459947574730059, 0.85599884568212969, 0.84999879758555175, 0.8560108698266119, 0.84799076545703789, 0.85598682153764749, 0.85200682971406583, 0.84999879758555175, 0.84801481374600185, 0.84001875766539202, 0.80599042878099214, 0.84601880576196997, 0.82999062116730393, 0.84399874948897391, 0.85401486184257991, 0.84600678161748799, 0.85401486184257991, 0.84201476564942401, 0.84601880576196997, 0.71797369117187315, 0.84600678161748799, 0.84402279777793809, 0.85996681336122938, 0.8100064930380203, 0.8359786451193999, 0.84001875766539202, 0.84999879758555175, 0.84999879758555175, 0.84603082990645218, 0.85602289397109399, 0.85197075728061955, 0.78793016376884795, 0.84800278960151987, 0.84800278960151987, 0.85199480556958374, 0.79194622802587589, 0.84399874948897391, 0.84601880576196997, 0.84801481374600185, 0.85199480556958374, 0.84999879758555175, 0.85403891013154409, 0.69994949859317501, 0.85001082173003384, 0.84600678161748799, 0.83801072553687794, 0.84999879758555175, 0.84999879758555175, 0.81603058942356255, 0.84999879758555175, 0.85401486184257991, 0.85002284587451593, 0.84199071736045983, 0.854026885987062, 0.83601471755284607, 0.85401486184257991, 0.85401486184257991, 0.84399874948897391, 0.85199480556958374, 0.84600678161748799, 0.84600678161748799, 0.85598682153764749, 0.84998677344106977, 0.84599475747300579, 0.70794555467378506, 0.8560108698266119, 0.84999879758555175, 0.8459947574730059, 0.84999879758555175, 0.84801481374600185, 0.84800278960151987, 0.84197869321597762, 0.77000216434600688, 0.85599884568212969, 0.85001082173003384, 0.8459947574730059, 0.84801481374600185, 0.84200274150494192, 0.85399081355361561, 0.85200682971406583, 0.84999879758555175, 0.84600678161748799, 0.84202678979390611, 0.85201885385854803, 0.85198278142510164, 0.84800278960151987, 0.84996272515210547, 0.84998677344106977, 0.81599451699011605, 0.84403482192242019, 0.85801890195512598, 0.85200682971406583, 0.8459947574730059, 0.84999879758555175, 0.85199480556958374, 0.84403482192242019, 0.84196666907149564, 0.84004280595435643, 0.85400283769809782]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'XYCDataset' object has no attribute 'get_label'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-edc3882e5a3b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m                                                   \u001b[0mdefault_cv_result\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'params'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                                                   \u001b[0mdefault_cv_result\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'best_n_estimators'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m                                                   custom_metric = {'roc_auc': roc_auc_score})\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mtrackers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdefault_test_result\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/py3/lib/python3.6/site-packages/modelgym-0.1.2.1-py3.6.egg/modelgym/trainer.py\u001b[0m in \u001b[0;36mfit_eval\u001b[0;34m(self, model, dtrain, dtest, params, n_estimators, custom_metric)\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_dtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# TODO: why 2 args?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmetric_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric_func\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcustom_metric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m                 \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetric_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_dtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# TODO weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m                 \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmetric_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'XYCDataset' object has no attribute 'get_label'"
     ]
    }
   ],
   "source": [
    "for model_id, model_class in CANDIDATES.items():\n",
    "    model = model_class(TASK_CLASSIFICATION)\n",
    "    print (\"~\"*20, model.get_name(), \"~\"*20)\n",
    "    trackers[model_id] = tracker_factory(model_name=model.get_name())\n",
    "    if LOAD_CACHE:\n",
    "        default_cv_result[model_id], default_test_result[model_id], tuned_cv_result[model_id], tuned_test_result[model_id], trials[model_id] = \\\n",
    "            trackers[model_id].load_state(as_list=True)\n",
    "    \n",
    "    \n",
    "    if default_cv_result[model_id] is None:\n",
    "        default_cv_result[model_id] = trainer.crossval_fit_eval(model, cv_pairs)\n",
    "        trackers[model_id].save_state(default_cv=default_cv_result[model_id])\n",
    "    trainer.print_result(default_cv_result[model_id], 'Default {} result on CV'.format(model.get_name()))\n",
    "\n",
    "    if default_test_result[model_id] is None:\n",
    "        default_test_result[model_id] = trainer.fit_eval(model, dtrain, dtest,\n",
    "                                                  default_cv_result[model_id]['params'],\n",
    "                                                  default_cv_result[model_id]['best_n_estimators'],\n",
    "                                                  custom_metric = {'roc_auc': roc_auc_score})\n",
    "        trackers[model_id].save_state(default_test=default_test_result[model_id])\n",
    "\n",
    "    trainer.print_result(default_test_result[model_id], 'Default {} result on TEST'.format(model.get_name()), extra_keys=['roc_auc'])\n",
    "\n",
    "        \n",
    "    if tuned_cv_result[model_id] is None:\n",
    "        print('Hyperopt iterations:\\n\\n')\n",
    "        tuned_cv_result[model_id] = trainer.crossval_optimize_params(model, cv_pairs,  algo_name=OPTIMIZER, \n",
    "                                                           trials=trials[model_id], tracker=trackers[model_id])\n",
    "        trackers[model_id].save_state(tuned_cv=tuned_cv_result[model_id])\n",
    "    trainer.print_result(tuned_cv_result[model_id], 'Tuned {} result on cv'.format(model.get_name()))\n",
    "\n",
    "    if tuned_test_result[model_id] is None:\n",
    "        tuned_test_result[model_id] = trainer.fit_eval(model, dtrain, dtest,\n",
    "                                            tuned_cv_result[model_id]['params'],\n",
    "                                            tuned_cv_result[model_id]['best_n_estimators'],\n",
    "                                            custom_metric = {'roc_auc': roc_auc_score})\n",
    "        trackers[model_id].save_state(tuned_test=tuned_test_result[model_id])\n",
    "    trainer.print_result(tuned_test_result[model_id], 'Tuned {} result on test'.format(model.get_name()), extra_keys=['roc_auc'])\n",
    "\n",
    "    trackers[model_id].save_state(default_cv=default_cv_result[model_id], default_test=default_test_result[model_id], \n",
    "                               tuned_cv=tuned_cv_result[model_id], tuned_test=tuned_test_result[model_id], trials=trials[model_id])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "metric, mes_min = 'roc_auc', False\n",
    "full_results = {}\n",
    "for i in CANDIDATES.keys():\n",
    "    if i in trackers:\n",
    "        tracker = trackers[i]\n",
    "    else:\n",
    "        tracker = tracker_factory(model_name=i)\n",
    "        tracker.load_state()\n",
    "    full_results.update({i:{'tuned': tracker.state['tuned_test'], 'default': tracker.state['default_test']}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_metric_results(full_results, index, metric, is_min_better=True):\n",
    "    test_results_list = []\n",
    "    for i in index:\n",
    "        test_results_list.append([full_results[i]['default'][metric], full_results[i]['tuned'][metric]])\n",
    "        \n",
    "    test_results = np.array(test_results_list)\n",
    "    if is_min_better:\n",
    "        baseline = test_results.min()\n",
    "    else:\n",
    "        baseline = test_results.max()\n",
    "    diff = 100 * test_results / baseline - 100\n",
    "    test_results_formatted = [['{:.6f} ({:+.2f}%)'.format(test_results[i, j], diff[i, j]) for j in range(2)] for i in range(len(index))]\n",
    "\n",
    "    print (pd.DataFrame(test_results_formatted, columns=['default', 'tuned'], index=index))\n",
    "    \n",
    "    full_names = [\" \".join(i) for i in itertools.product(index, ['default', 'tuned'])]\n",
    "\n",
    "    named_results = zip(full_names, test_results.flatten())\n",
    "\n",
    "    sorted_results = sorted(named_results, key=lambda x: x[1], reverse=not is_min_better)\n",
    "    xticks = ['%s\\n%.5f' % (name, loss) for name, loss in sorted_results]\n",
    "\n",
    "    pyplot.figure(figsize=(20, 7))\n",
    "    pyplot.scatter(range(len(full_names)), list(zip(*sorted_results))[1], s=150)\n",
    "    pyplot.xticks(range(len(full_names)), xticks, fontsize=15)\n",
    "    pyplot.yticks(fontsize=12)\n",
    "    pyplot.title('Comparison', fontsize=20)\n",
    "    pyplot.ylabel(metric, fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%pylab inline --no-import-all\n",
    "metric, is_min_better = 'roc_auc', False\n",
    "plot_metric_results(full_results, CANDIDATES.keys(), metric, is_min_better=is_min_better)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
