{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#from modelgym import model\n",
    "import functools\n",
    "import modelgym\n",
    "from modelgym.util import TASK_CLASSIFICATION\n",
    "from modelgym.trainer import Trainer\n",
    "from modelgym.tracker import ProgressTrackerFile, ProgressTrackerMongo\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from hyperopt.mongoexp import MongoTrials\n",
    "from modelgym.util import split_and_preprocess\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using File as backend for tracking\n",
      "Running experiment cofiguration: test\n"
     ]
    }
   ],
   "source": [
    "########### NROWS, N_ESTIMATORS, N_PROBES, TEST_SIZE, N_CV_SPLITS, OPTIMIZER\n",
    "config_tuple = {\n",
    "    'test': (1000, 100,  2, 0.5, 2, 'random'),\n",
    "    'pror': (None, 1000, 100, 0.5, 2, 'random'), # production with random hyperopt suggestor\n",
    "    'prot': (None, 1000, 100, 0.5, 2, 'tpe'),    # production with tpe hyperopt suggestor\n",
    "    'demi': (10000, 100, 5, 0.5, 2, 'random')\n",
    "}\n",
    "CONFIG = 'test' if 'EXP_CONFIG' not in os.environ else os.environ['EXP_CONFIG']\n",
    "NROWS, N_ESTIMATORS, N_PROBES, TEST_SIZE, N_CV_SPLITS, OPTIMIZER = config_tuple[CONFIG]\n",
    "CANDIDATES = OrderedDict([\n",
    "    ('XGBoost', modelgym.XGBModel), \n",
    "    ('LightGBM', modelgym.LGBModel),\n",
    "    ('RandomForestClassifier',modelgym.RFModel)\n",
    "])\n",
    "RESULTS_DIR = \"results\"\n",
    "LOAD_CACHE = False\n",
    "if 'MONGO_PORT_27017_TCP_ADDR' in os.environ:\n",
    "    mongo_host = os.environ['MONGO_PORT_27017_TCP_ADDR'] if 'MONGO_PORT_27017_TCP_ADDR' in os.environ else 'cern-mc01h'\n",
    "    mongo_port = int(os.environ['MONGO_PORT_27017_TCP_PORT']) if 'MONGO_PORT_27017_TCP_PORT' in os.environ else 27017\n",
    "    mongo_db = os.environ['MONGO_DB'] if 'MONGO_DB' in os.environ else 'trials'\n",
    "    tracker_factory = functools.partial(ProgressTrackerMongo, mongo_host, mongo_port, mongo_db, config_key=CONFIG)\n",
    "    print (\"Using Mongo as backend for tracking\")\n",
    "else:\n",
    "    tracker_factory = functools.partial(ProgressTrackerFile, RESULTS_DIR, config_key=CONFIG)\n",
    "    print (\"Using File as backend for tracking\")\n",
    "\n",
    "print (\"Running experiment cofiguration:\", CONFIG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download & read data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 266224\n",
      "-rw-r--r--  1 macbook  staff  136304022 Aug 11 14:40 XY2d.pickle\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "if [ ! -d data ] ; then \n",
    "    mkdir data \n",
    "    cd data\n",
    "    curl https://cernbox.cern.ch/index.php/s/N1dpSAPgl30szYM/download | gunzip -c > XY2d.pickle\n",
    "    cd ..\n",
    "fi\n",
    "ls -l data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_data(fname, nrows=None, shuffle=True):\n",
    "    with open(fname,'rb') as fh:\n",
    "        X, y = pickle.load(fh,encoding='bytes')\n",
    "    index = np.arange(X.shape[0])\n",
    "    if nrows is None:\n",
    "        nrows = X.shape[0]\n",
    "    weights = np.ones(nrows) # uh, well...\n",
    "    if shuffle:\n",
    "        index_perm = np.random.permutation(index)\n",
    "    else:\n",
    "        index_perm = index\n",
    "    return X[index_perm[:nrows]], y[index_perm[:nrows]], weights\n",
    "\n",
    "\n",
    "X, y, weights = read_data(\"data/XY2d.pickle\", nrows=NROWS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, w_train, w_test = train_test_split(X, y, weights, test_size=TEST_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv_pairs, (dtrain, dtest) = split_and_preprocess(X_train.copy(), y_train, \n",
    "                                                X_test.copy(), y_test, \n",
    "                                                cat_cols=[], n_splits=N_CV_SPLITS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run them all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trackers = {}\n",
    "def init_keys_dict():\n",
    "    return dict([(k, None) for k in CANDIDATES.keys()])\n",
    "default_cv_result = init_keys_dict()\n",
    "tuned_cv_result = init_keys_dict()\n",
    "default_test_result = init_keys_dict()\n",
    "tuned_test_result = init_keys_dict()\n",
    "trials = init_keys_dict()\n",
    "trainer = Trainer(hyperopt_evals=N_PROBES, n_estimators=N_ESTIMATORS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~~ XGBoost ~~~~~~~~~~~~~~~~~~~~\n",
      "BST  <xgboost.core.Booster object at 0x114b31898>\n",
      "RES [0.645166, 0.604997, 0.571197, 0.545222, 0.521121, 0.499799, 0.483152, 0.470253, 0.457933, 0.447555, 0.438444, 0.431717, 0.42802, 0.422819, 0.418252, 0.41592, 0.413867, 0.410783, 0.40885, 0.405599, 0.404212, 0.405371, 0.403347, 0.404033, 0.406353, 0.405289, 0.406975, 0.40633, 0.409409, 0.409972, 0.410956, 0.412066, 0.413743, 0.414197, 0.414309, 0.416741, 0.416374, 0.417333, 0.415887, 0.41672, 0.41837, 0.421017, 0.421979, 0.422518, 0.422346, 0.42419, 0.426285, 0.427579, 0.43033, 0.431335, 0.432816, 0.432099, 0.435316, 0.436437, 0.436352, 0.435109, 0.435982, 0.436045, 0.437982, 0.437894, 0.438316, 0.436445, 0.43798, 0.438334, 0.437705, 0.436744, 0.438719, 0.440408, 0.440037, 0.438699, 0.43839, 0.436892, 0.436172, 0.437108, 0.437643, 0.438197, 0.436654, 0.437859, 0.439529, 0.440459, 0.44285, 0.444436, 0.445137, 0.445584, 0.446445, 0.446317, 0.447743, 0.448817, 0.449458, 0.450159, 0.452289, 0.451224, 0.451839, 0.45319, 0.452081, 0.451165, 0.452335, 0.453294, 0.45484, 0.455698]\n",
      "BST  <xgboost.core.Booster object at 0x114b31940>\n",
      "RES [0.643106, 0.603301, 0.5711, 0.545003, 0.522551, 0.502639, 0.488622, 0.474853, 0.464432, 0.455226, 0.448095, 0.443202, 0.439611, 0.430514, 0.427198, 0.422563, 0.421959, 0.416433, 0.415091, 0.414334, 0.412597, 0.412323, 0.409564, 0.408536, 0.409591, 0.41079, 0.410576, 0.409392, 0.407647, 0.405459, 0.405472, 0.405059, 0.403968, 0.402591, 0.403066, 0.403593, 0.403284, 0.404036, 0.40589, 0.406816, 0.405626, 0.406045, 0.40769, 0.40956, 0.409898, 0.411806, 0.412831, 0.412005, 0.412021, 0.411692, 0.410589, 0.410193, 0.410099, 0.408795, 0.409717, 0.409552, 0.412141, 0.413207, 0.414474, 0.413894, 0.413443, 0.413564, 0.41494, 0.417198, 0.417015, 0.417537, 0.418608, 0.420525, 0.420846, 0.421335, 0.420752, 0.422294, 0.422486, 0.423854, 0.42546, 0.426557, 0.426291, 0.427439, 0.428954, 0.431103, 0.432927, 0.433337, 0.43272, 0.436069, 0.437519, 0.438703, 0.440003, 0.440149, 0.439166, 0.439236, 0.441573, 0.441612, 0.441423, 0.443499, 0.444076, 0.443958, 0.444363, 0.445718, 0.446913, 0.448824]\n",
      "saved state to results/tracker_test_XGBoost.pickle\n",
      "Default XGBoost result on CV:\n",
      "\n",
      "loss = 0.4062845\n",
      "best_n_estimators = 24\n",
      "params = {'base_score': 0.5, 'colsample_bylevel': 1, 'colsample_bytree': 1, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 3, 'min_child_weight': 1, 'missing': None, 'n_estimators': 100, 'nthread': -1, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': 0, 'subsample': 1, 'objective': 'binary:logistic', 'eval_metric': 'logloss', 'silent': 1}\n",
      "BST  <xgboost.core.Booster object at 0x114b17ba8>\n",
      "RES [0.64372, 0.606227, 0.57183, 0.545822, 0.521552, 0.502938, 0.485371, 0.469952, 0.458404, 0.448106, 0.436382, 0.42878, 0.420775, 0.413812, 0.409036, 0.403224, 0.397827, 0.394173, 0.389925, 0.387748, 0.384266, 0.380649, 0.378193, 0.374722]\n",
      "saved state to results/tracker_test_XGBoost.pickle\n",
      "Default XGBoost result on TEST:\n",
      "\n",
      "loss = 0.374722\n",
      "n_estimators = 24\n",
      "params = {'base_score': 0.5, 'colsample_bylevel': 1, 'colsample_bytree': 1, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 3, 'min_child_weight': 1, 'missing': None, 'n_estimators': 100, 'nthread': -1, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': 0, 'subsample': 1, 'objective': 'binary:logistic', 'eval_metric': 'logloss', 'silent': 1}\n",
      "roc_auc = 0.821818\n",
      "Hyperopt iterations:\n",
      "\n",
      "\n",
      "BST  <xgboost.core.Booster object at 0x114b31940>\n",
      "RES [0.588794, 0.524755, 0.477347, 0.447827, 0.424319, 0.407258, 0.40724, 0.39232, 0.387198, 0.38077, 0.389231, 0.394217, 0.398557, 0.395766, 0.405631, 0.404415, 0.409028, 0.416998, 0.423484, 0.433454, 0.432102, 0.442097, 0.452671, 0.454071, 0.470381, 0.486012, 0.494748, 0.502468, 0.513969, 0.517539, 0.524988, 0.520977, 0.518606, 0.517722, 0.531949, 0.533176, 0.541684, 0.544198, 0.544106, 0.545298, 0.54709, 0.54928, 0.546966, 0.550704, 0.553498, 0.55313, 0.558216, 0.560886, 0.563294, 0.567745, 0.563134, 0.565893, 0.568125, 0.573611, 0.574472, 0.569624, 0.570777, 0.567313, 0.57545, 0.581127, 0.579683, 0.578658, 0.579316, 0.584882, 0.582346, 0.583241, 0.586359, 0.582788, 0.579871, 0.583557, 0.580793, 0.580482, 0.578253, 0.575324, 0.572312, 0.57554, 0.58001, 0.580451, 0.586603, 0.584673, 0.583988, 0.581452, 0.581528, 0.58143, 0.587378, 0.593437, 0.591184, 0.588595, 0.589857, 0.585727, 0.586777, 0.58367, 0.585305, 0.583561, 0.583475, 0.578987, 0.580503, 0.581369, 0.580253, 0.587857]\n",
      "BST  <xgboost.core.Booster object at 0x107f11828>\n",
      "RES [0.593884, 0.533871, 0.483593, 0.448997, 0.42795, 0.424081, 0.411809, 0.399141, 0.390403, 0.401629, 0.403209, 0.406153, 0.418434, 0.432834, 0.447713, 0.465322, 0.457687, 0.46786, 0.466744, 0.478234, 0.482158, 0.49565, 0.49864, 0.508665, 0.522836, 0.529148, 0.545781, 0.547644, 0.547348, 0.553698, 0.558676, 0.556142, 0.5608, 0.562901, 0.569938, 0.573975, 0.579219, 0.581417, 0.584789, 0.581572, 0.586467, 0.587758, 0.588059, 0.590368, 0.597896, 0.593603, 0.595179, 0.596481, 0.604367, 0.597408, 0.604905, 0.60377, 0.606416, 0.609817, 0.611365, 0.610271, 0.61574, 0.621511, 0.622942, 0.621074, 0.620296, 0.618513, 0.623551, 0.621546, 0.618568, 0.620501, 0.623508, 0.629562, 0.632773, 0.639155, 0.642897, 0.638965, 0.644345, 0.64409, 0.644729, 0.646437, 0.65334, 0.656607, 0.657934, 0.661262, 0.666356, 0.670316, 0.668015, 0.665776, 0.666672, 0.663805, 0.665662, 0.667972, 0.670314, 0.672708, 0.679142, 0.676797, 0.683098, 0.686179, 0.686093, 0.682922, 0.679311, 0.681295, 0.683364, 0.687235]\n",
      "[1/2]\teval_time=0.22 sec\tcurrent_logloss=0.388800\tmin_logloss=0.388800\n",
      "BST  <xgboost.core.Booster object at 0x127d02fd0>\n",
      "RES [0.538704, 0.463282, 0.418946, 0.409626, 0.403251, 0.395592, 0.406981, 0.42013, 0.43831, 0.458302, 0.481305, 0.518997, 0.537803, 0.566973, 0.589678, 0.606647, 0.599543, 0.615569, 0.640818, 0.662827, 0.663075, 0.677676, 0.708783, 0.701152, 0.730414, 0.739966, 0.755346, 0.764678, 0.782769, 0.789018, 0.777974, 0.781328, 0.800878, 0.797239, 0.807415, 0.827099, 0.82897, 0.835112, 0.85055, 0.869276, 0.874509, 0.897921, 0.894753, 0.895239, 0.893878, 0.897838, 0.89421, 0.899257, 0.905296, 0.903059, 0.899512, 0.902778, 0.905108, 0.907778, 0.905797, 0.904507, 0.904965, 0.903023, 0.902413, 0.90348, 0.904082, 0.903748, 0.906063, 0.906059, 0.905099, 0.907467, 0.907377, 0.912601, 0.912777, 0.907871, 0.907613, 0.911653, 0.910112, 0.914122, 0.905621, 0.906519, 0.907136, 0.905283, 0.907641, 0.906115, 0.908762, 0.910738, 0.909714, 0.90953, 0.904932, 0.909656, 0.907632, 0.911311, 0.911665, 0.910575, 0.908816, 0.906672, 0.908315, 0.907596, 0.910795, 0.912452, 0.912896, 0.908552, 0.903954, 0.90907]\n",
      "BST  <xgboost.core.Booster object at 0x127d02e10>\n",
      "RES [0.546555, 0.503476, 0.516744, 0.523283, 0.53266, 0.523186, 0.536934, 0.535957, 0.534981, 0.549698, 0.575719, 0.581189, 0.593443, 0.607541, 0.620851, 0.625223, 0.648957, 0.670433, 0.677272, 0.692596, 0.714658, 0.742444, 0.773612, 0.798179, 0.813557, 0.832029, 0.843112, 0.855828, 0.892334, 0.919856, 0.960165, 0.973756, 0.974212, 0.992692, 1.00666, 1.003448, 1.012834, 1.015054, 1.030591, 1.034223, 1.036822, 1.034951, 1.04762, 1.043569, 1.042817, 1.043292, 1.043994, 1.045004, 1.046238, 1.048272, 1.046682, 1.044562, 1.042204, 1.037017, 1.048536, 1.051379, 1.05079, 1.050579, 1.050153, 1.051296, 1.05178, 1.048501, 1.046427, 1.047401, 1.047632, 1.047863, 1.046987, 1.050685, 1.048495, 1.047213, 1.043858, 1.045494, 1.047644, 1.049641, 1.048881, 1.046941, 1.045496, 1.046255, 1.045517, 1.047679, 1.046539, 1.04596, 1.050068, 1.048441, 1.046025, 1.050689, 1.049574, 1.047115, 1.048322, 1.045588, 1.04684, 1.046382, 1.048416, 1.052492, 1.049372, 1.049767, 1.047858, 1.047387, 1.046739, 1.049364]\n",
      "[2/2]\teval_time=0.18 sec\tcurrent_logloss=0.459389\tmin_logloss=0.388800\n",
      "saved state to results/tracker_test_XGBoost.pickle\n",
      "saved state to results/tracker_test_XGBoost.pickle\n",
      "Tuned XGBoost result on cv:\n",
      "\n",
      "loss = 0.3888005\n",
      "best_n_estimators = 9\n",
      "params = {'alpha': 0, 'colsample_bylevel': 0.7405046763756069, 'colsample_bytree': 0.6151399892026908, 'eta': 0.22398969443165967, 'gamma': 5.745168482871384e-07, 'lambda': 0.019440307789833522, 'max_depth': 10, 'min_child_weight': 0.16853765259109013, 'subsample': 0.6197753137030573, 'objective': 'binary:logistic', 'eval_metric': 'logloss', 'silent': 1}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BST  <xgboost.core.Booster object at 0x114a9b128>\n",
      "RES [0.581706, 0.520122, 0.476729, 0.441705, 0.419584, 0.403764, 0.393133, 0.388028, 0.383553]\n",
      "saved state to results/tracker_test_XGBoost.pickle\n",
      "Tuned XGBoost result on test:\n",
      "\n",
      "loss = 0.383553\n",
      "n_estimators = 9\n",
      "params = {'alpha': 0, 'colsample_bylevel': 0.7405046763756069, 'colsample_bytree': 0.6151399892026908, 'eta': 0.22398969443165967, 'gamma': 5.745168482871384e-07, 'lambda': 0.019440307789833522, 'max_depth': 10, 'min_child_weight': 0.16853765259109013, 'subsample': 0.6197753137030573, 'objective': 'binary:logistic', 'eval_metric': 'logloss', 'silent': 1}\n",
      "roc_auc = 0.795866\n",
      "saved state to results/tracker_test_XGBoost.pickle\n",
      "~~~~~~~~~~~~~~~~~~~~ LightGBM ~~~~~~~~~~~~~~~~~~~~\n",
      "saved state to results/tracker_test_LightGBM.pickle\n",
      "Default LightGBM result on CV:\n",
      "\n",
      "loss = 0.420222992316\n",
      "best_n_estimators = 22\n",
      "params = {'boosting_type': 'gbdt', 'colsample_bytree': 1, 'drop_rate': 0.1, 'is_unbalance': False, 'learning_rate': 0.1, 'max_bin': 255, 'min_data_in_leaf': 20, 'max_depth': -1, 'max_drop': 50, 'min_child_samples': 10, 'min_child_weight': 5, 'min_split_gain': 0, 'min_sum_hessian_in_leaf': 0.001, 'lambda_l1': 0, 'lambda_l2': 0, 'n_estimators': 10, 'nthread': 4, 'num_threads': 4, 'num_leaves': 31, 'reg_alpha': 0, 'reg_lambda': 0, 'scale_pos_weight': 1, 'seed': 0, 'sigmoid': 1.0, 'skip_drop': 0.5, 'subsample': 1, 'subsample_for_bin': 50000, 'subsample_freq': 1, 'uniform_drop': False, 'xgboost_dart_mode': False, 'objective': 'binary', 'metric': 'binary_logloss', 'bagging_freq': 1, 'verbose': -1}\n",
      "saved state to results/tracker_test_LightGBM.pickle\n",
      "Default LightGBM result on TEST:\n",
      "\n",
      "loss = 0.363739056242\n",
      "n_estimators = 22\n",
      "params = {'boosting_type': 'gbdt', 'colsample_bytree': 1, 'drop_rate': 0.1, 'is_unbalance': False, 'learning_rate': 0.1, 'max_bin': 255, 'min_data_in_leaf': 20, 'max_depth': -1, 'max_drop': 50, 'min_child_samples': 10, 'min_child_weight': 5, 'min_split_gain': 0, 'min_sum_hessian_in_leaf': 0.001, 'lambda_l1': 0, 'lambda_l2': 0, 'n_estimators': 10, 'nthread': 4, 'num_threads': 4, 'num_leaves': 31, 'reg_alpha': 0, 'reg_lambda': 0, 'scale_pos_weight': 1, 'seed': 0, 'sigmoid': 1.0, 'skip_drop': 0.5, 'subsample': 1, 'subsample_for_bin': 50000, 'subsample_freq': 1, 'uniform_drop': False, 'xgboost_dart_mode': False, 'objective': 'binary', 'metric': 'binary_logloss', 'bagging_freq': 1, 'verbose': -1}\n",
      "roc_auc = 0.825666\n",
      "Hyperopt iterations:\n",
      "\n",
      "\n",
      "[1/2]\teval_time=0.09 sec\tcurrent_logloss=0.693147\tmin_logloss=0.693147\n",
      "[2/2]\teval_time=1.14 sec\tcurrent_logloss=0.591534\tmin_logloss=0.591534\n",
      "saved state to results/tracker_test_LightGBM.pickle\n",
      "saved state to results/tracker_test_LightGBM.pickle\n",
      "Tuned LightGBM result on cv:\n",
      "\n",
      "loss = 0.5915338890427485\n",
      "best_n_estimators = 100\n",
      "params = {'bagging_fraction': 0.5292435929542255, 'feature_fraction': 0.9444627024858503, 'lambda_l1': 0, 'lambda_l2': 0, 'learning_rate': 0.0025275717184566064, 'min_data_in_leaf': 10, 'min_sum_hessian_in_leaf': 4.1073662953607967e-07, 'num_leaves': 137, 'objective': 'binary', 'metric': 'binary_logloss', 'bagging_freq': 1, 'verbose': -1, 'max_bin': 255}\n",
      "saved state to results/tracker_test_LightGBM.pickle\n",
      "Tuned LightGBM result on test:\n",
      "\n",
      "loss = 0.582381142759\n",
      "n_estimators = 100\n",
      "params = {'bagging_fraction': 0.5292435929542255, 'feature_fraction': 0.9444627024858503, 'lambda_l1': 0, 'lambda_l2': 0, 'learning_rate': 0.0025275717184566064, 'min_data_in_leaf': 10, 'min_sum_hessian_in_leaf': 4.1073662953607967e-07, 'num_leaves': 137, 'objective': 'binary', 'metric': 'binary_logloss', 'bagging_freq': 1, 'verbose': -1, 'max_bin': 255}\n",
      "roc_auc = 0.828222\n",
      "saved state to results/tracker_test_LightGBM.pickle\n",
      "~~~~~~~~~~~~~~~~~~~~ RandomForestClassifier ~~~~~~~~~~~~~~~~~~~~\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'best' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-edc3882e5a3b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdefault_cv_result\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_id\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mdefault_cv_result\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_id\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcrossval_fit_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv_pairs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mtrackers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault_cv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdefault_cv_result\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault_cv_result\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Default {} result on CV'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/py3/lib/python3.6/site-packages/modelgym-0.1.2.1-py3.6.egg/modelgym/trainer.py\u001b[0m in \u001b[0;36mcrossval_fit_eval\u001b[0;34m(self, model, cv_pairs, params, n_estimators, verbose)\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0m_dtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat_cols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0m_dtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat_cols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevals_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_dtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_dtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_estimators\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m             \u001b[0mevals_results\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mmean_evals_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevals_results\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/py3/lib/python3.6/site-packages/modelgym-0.1.2.1-py3.6.egg/modelgym/rf_model.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, params, dtrain, dtest, n_estimators)\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'status'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSTATUS_OK\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0mbest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspace4rf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malgo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtpe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuggest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_evals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m         \u001b[0mxxx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mspace_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspace4rf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxxx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/py3/lib/python3.6/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin)\u001b[0m\n\u001b[1;32m    318\u001b[0m                     verbose=verbose)\n\u001b[1;32m    319\u001b[0m     \u001b[0mrval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m     \u001b[0mrval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexhaust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreturn_argmin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtrials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/py3/lib/python3.6/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mexhaust\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexhaust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0mn_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_evals\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mn_done\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock_until_done\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/py3/lib/python3.6/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, N, block_until_done)\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m                 \u001b[0;31m# -- loop over trials and do the jobs directly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserial_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstopped\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/py3/lib/python3.6/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mserial_evaluate\u001b[0;34m(self, N)\u001b[0m\n\u001b[1;32m     90\u001b[0m                 \u001b[0mctrl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCtrl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_trial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdomain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctrl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'job exception: %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/py3/lib/python3.6/site-packages/hyperopt/base.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[1;32m    838\u001b[0m                 \u001b[0mmemo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmemo\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    839\u001b[0m                 print_node_on_error=self.rec_eval_print_node_on_error)\n\u001b[0;32m--> 840\u001b[0;31m             \u001b[0mrval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpyll_rval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/py3/lib/python3.6/site-packages/modelgym-0.1.2.1-py3.6.egg/modelgym/rf_model.py\u001b[0m in \u001b[0;36mf\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhyperopt_train_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0;31m#global best\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbest\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m                 \u001b[0mbest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'new best:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'best' referenced before assignment"
     ]
    }
   ],
   "source": [
    "for model_id, model_class in CANDIDATES.items():\n",
    "    model = model_class(TASK_CLASSIFICATION)\n",
    "    print (\"~\"*20, model.get_name(), \"~\"*20)\n",
    "    trackers[model_id] = tracker_factory(model_name=model.get_name())\n",
    "    if LOAD_CACHE:\n",
    "        default_cv_result[model_id], default_test_result[model_id], tuned_cv_result[model_id], tuned_test_result[model_id], trials[model_id] = \\\n",
    "            trackers[model_id].load_state(as_list=True)\n",
    "    \n",
    "    \n",
    "    if default_cv_result[model_id] is None:\n",
    "        default_cv_result[model_id] = trainer.crossval_fit_eval(model, cv_pairs)\n",
    "        trackers[model_id].save_state(default_cv=default_cv_result[model_id])\n",
    "    trainer.print_result(default_cv_result[model_id], 'Default {} result on CV'.format(model.get_name()))\n",
    "\n",
    "    if default_test_result[model_id] is None:\n",
    "        default_test_result[model_id] = trainer.fit_eval(model, dtrain, dtest,\n",
    "                                                  default_cv_result[model_id]['params'],\n",
    "                                                  default_cv_result[model_id]['best_n_estimators'],\n",
    "                                                  custom_metric = {'roc_auc': roc_auc_score})\n",
    "        trackers[model_id].save_state(default_test=default_test_result[model_id])\n",
    "\n",
    "    trainer.print_result(default_test_result[model_id], 'Default {} result on TEST'.format(model.get_name()), extra_keys=['roc_auc'])\n",
    "\n",
    "        \n",
    "    if tuned_cv_result[model_id] is None:\n",
    "        print('Hyperopt iterations:\\n\\n')\n",
    "        tuned_cv_result[model_id] = trainer.crossval_optimize_params(model, cv_pairs,  algo_name=OPTIMIZER, \n",
    "                                                           trials=trials[model_id], tracker=trackers[model_id])\n",
    "        trackers[model_id].save_state(tuned_cv=tuned_cv_result[model_id])\n",
    "    trainer.print_result(tuned_cv_result[model_id], 'Tuned {} result on cv'.format(model.get_name()))\n",
    "\n",
    "    if tuned_test_result[model_id] is None:\n",
    "        tuned_test_result[model_id] = trainer.fit_eval(model, dtrain, dtest,\n",
    "                                            tuned_cv_result[model_id]['params'],\n",
    "                                            tuned_cv_result[model_id]['best_n_estimators'],\n",
    "                                            custom_metric = {'roc_auc': roc_auc_score})\n",
    "        trackers[model_id].save_state(tuned_test=tuned_test_result[model_id])\n",
    "    trainer.print_result(tuned_test_result[model_id], 'Tuned {} result on test'.format(model.get_name()), extra_keys=['roc_auc'])\n",
    "\n",
    "    trackers[model_id].save_state(default_cv=default_cv_result[model_id], default_test=default_test_result[model_id], \n",
    "                               tuned_cv=tuned_cv_result[model_id], tuned_test=tuned_test_result[model_id], trials=trials[model_id])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "metric, mes_min = 'roc_auc', False\n",
    "full_results = {}\n",
    "for i in CANDIDATES.keys():\n",
    "    if i in trackers:\n",
    "        tracker = trackers[i]\n",
    "    else:\n",
    "        tracker = tracker_factory(model_name=i)\n",
    "        tracker.load_state()\n",
    "    full_results.update({i:{'tuned': tracker.state['tuned_test'], 'default': tracker.state['default_test']}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_metric_results(full_results, index, metric, is_min_better=True):\n",
    "    test_results_list = []\n",
    "    for i in index:\n",
    "        test_results_list.append([full_results[i]['default'][metric], full_results[i]['tuned'][metric]])\n",
    "        \n",
    "    test_results = np.array(test_results_list)\n",
    "    if is_min_better:\n",
    "        baseline = test_results.min()\n",
    "    else:\n",
    "        baseline = test_results.max()\n",
    "    diff = 100 * test_results / baseline - 100\n",
    "    test_results_formatted = [['{:.6f} ({:+.2f}%)'.format(test_results[i, j], diff[i, j]) for j in range(2)] for i in range(len(index))]\n",
    "\n",
    "    print (pd.DataFrame(test_results_formatted, columns=['default', 'tuned'], index=index))\n",
    "    \n",
    "    full_names = [\" \".join(i) for i in itertools.product(index, ['default', 'tuned'])]\n",
    "\n",
    "    named_results = zip(full_names, test_results.flatten())\n",
    "\n",
    "    sorted_results = sorted(named_results, key=lambda x: x[1], reverse=not is_min_better)\n",
    "    xticks = ['%s\\n%.5f' % (name, loss) for name, loss in sorted_results]\n",
    "\n",
    "    pyplot.figure(figsize=(20, 7))\n",
    "    pyplot.scatter(range(len(full_names)), list(zip(*sorted_results))[1], s=150)\n",
    "    pyplot.xticks(range(len(full_names)), xticks, fontsize=15)\n",
    "    pyplot.yticks(fontsize=12)\n",
    "    pyplot.title('Comparison', fontsize=20)\n",
    "    pyplot.ylabel(metric, fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%pylab inline --no-import-all\n",
    "metric, is_min_better = 'roc_auc', False\n",
    "plot_metric_results(full_results, CANDIDATES.keys(), metric, is_min_better=is_min_better)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
