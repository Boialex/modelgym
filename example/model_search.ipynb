{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#from modelgym import model\n",
    "import functools\n",
    "import modelgym\n",
    "from modelgym.util import TASK_CLASSIFICATION\n",
    "from modelgym.trainer import Trainer\n",
    "from modelgym.tracker import ProgressTrackerFile, ProgressTrackerMongo\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from hyperopt.mongoexp import MongoTrials\n",
    "from modelgym.util import split_and_preprocess\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using File as backend for tracking\n",
      "Running experiment cofiguration: test\n"
     ]
    }
   ],
   "source": [
    "########### NROWS, N_ESTIMATORS, N_PROBES, TEST_SIZE, N_CV_SPLITS, OPTIMIZER\n",
    "config_tuple = {\n",
    "    'test': (1000, 100,  2, 0.5, 2, 'random'),\n",
    "    'pror': (None, 1000, 100, 0.5, 2, 'random'), # production with random hyperopt suggestor\n",
    "    'prot': (None, 1000, 100, 0.5, 2, 'tpe'),    # production with tpe hyperopt suggestor\n",
    "    'demi': (10000, 100, 5, 0.5, 2, 'random')\n",
    "}\n",
    "CONFIG = 'test' if 'EXP_CONFIG' not in os.environ else os.environ['EXP_CONFIG']\n",
    "NROWS, N_ESTIMATORS, N_PROBES, TEST_SIZE, N_CV_SPLITS, OPTIMIZER = config_tuple[CONFIG]\n",
    "CANDIDATES = OrderedDict([\n",
    "    ('XGBoost', modelgym.XGBModel), \n",
    "    ('LightGBM', modelgym.LGBModel),\n",
    "    ('RandomForestClassifier',modelgym.RFModel)\n",
    "])\n",
    "RESULTS_DIR = \"results\"\n",
    "LOAD_CACHE = False\n",
    "if 'MONGO_PORT_27017_TCP_ADDR' in os.environ:\n",
    "    mongo_host = os.environ['MONGO_PORT_27017_TCP_ADDR'] if 'MONGO_PORT_27017_TCP_ADDR' in os.environ else 'cern-mc01h'\n",
    "    mongo_port = int(os.environ['MONGO_PORT_27017_TCP_PORT']) if 'MONGO_PORT_27017_TCP_PORT' in os.environ else 27017\n",
    "    mongo_db = os.environ['MONGO_DB'] if 'MONGO_DB' in os.environ else 'trials'\n",
    "    tracker_factory = functools.partial(ProgressTrackerMongo, mongo_host, mongo_port, mongo_db, config_key=CONFIG)\n",
    "    print (\"Using Mongo as backend for tracking\")\n",
    "else:\n",
    "    tracker_factory = functools.partial(ProgressTrackerFile, RESULTS_DIR, config_key=CONFIG)\n",
    "    print (\"Using File as backend for tracking\")\n",
    "\n",
    "print (\"Running experiment cofiguration:\", CONFIG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download & read data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 266224\n",
      "-rw-r--r--  1 macbook  staff  136304022 Aug 11 14:40 XY2d.pickle\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "if [ ! -d data ] ; then \n",
    "    mkdir data \n",
    "    cd data\n",
    "    curl https://cernbox.cern.ch/index.php/s/N1dpSAPgl30szYM/download | gunzip -c > XY2d.pickle\n",
    "    cd ..\n",
    "fi\n",
    "ls -l data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_data(fname, nrows=None, shuffle=True):\n",
    "    with open(fname,'rb') as fh:\n",
    "        X, y = pickle.load(fh,encoding='bytes')\n",
    "    index = np.arange(X.shape[0])\n",
    "    if nrows is None:\n",
    "        nrows = X.shape[0]\n",
    "    weights = np.ones(nrows) # uh, well...\n",
    "    if shuffle:\n",
    "        index_perm = np.random.permutation(index)\n",
    "    else:\n",
    "        index_perm = index\n",
    "    return X[index_perm[:nrows]], y[index_perm[:nrows]], weights\n",
    "\n",
    "\n",
    "X, y, weights = read_data(\"data/XY2d.pickle\", nrows=NROWS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, w_train, w_test = train_test_split(X, y, weights, test_size=TEST_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv_pairs, (dtrain, dtest) = split_and_preprocess(X_train.copy(), y_train, \n",
    "                                                X_test.copy(), y_test, \n",
    "                                                cat_cols=[], n_splits=N_CV_SPLITS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run them all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trackers = {}\n",
    "def init_keys_dict():\n",
    "    return dict([(k, None) for k in CANDIDATES.keys()])\n",
    "default_cv_result = init_keys_dict()\n",
    "tuned_cv_result = init_keys_dict()\n",
    "default_test_result = init_keys_dict()\n",
    "tuned_test_result = init_keys_dict()\n",
    "trials = init_keys_dict()\n",
    "trainer = Trainer(hyperopt_evals=N_PROBES, n_estimators=N_ESTIMATORS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~~ XGBoost ~~~~~~~~~~~~~~~~~~~~\n",
      "BST  <xgboost.core.Booster object at 0x11ba5e860>\n",
      "RES [0.64834, 0.613588, 0.579124, 0.553156, 0.531911, 0.51178, 0.498368, 0.48626, 0.471671, 0.460346, 0.451913, 0.4434, 0.434178, 0.427874, 0.422223, 0.416232, 0.410336, 0.409307, 0.40522, 0.403873, 0.39925, 0.395655, 0.395225, 0.392728, 0.390809, 0.39105, 0.389073, 0.388983, 0.387494, 0.387394, 0.386772, 0.386518, 0.386605, 0.390619, 0.391758, 0.393327, 0.392117, 0.392921, 0.394343, 0.398404, 0.396895, 0.398934, 0.399838, 0.398764, 0.402347, 0.403971, 0.404857, 0.404412, 0.405809, 0.40757, 0.408082, 0.405352, 0.406318, 0.406161, 0.407693, 0.410377, 0.408491, 0.41, 0.408896, 0.411079, 0.410914, 0.412946, 0.412625, 0.41353, 0.415453, 0.416017, 0.417886, 0.418556, 0.419715, 0.420142, 0.420288, 0.419522, 0.421604, 0.423237, 0.425535, 0.42517, 0.426509, 0.4267, 0.428924, 0.43041, 0.430087, 0.430419, 0.432133, 0.433322, 0.434188, 0.435031, 0.435541, 0.438144, 0.437668, 0.437895, 0.439896, 0.439907, 0.442103, 0.44405, 0.444144, 0.444082, 0.44412, 0.444995, 0.443867, 0.443049]\n",
      "BST  <xgboost.core.Booster object at 0x11ba5e908>\n",
      "RES [0.64616, 0.606004, 0.575222, 0.549075, 0.526792, 0.509723, 0.494204, 0.479252, 0.467591, 0.458179, 0.451671, 0.443207, 0.438031, 0.432163, 0.427756, 0.424533, 0.420834, 0.416891, 0.413192, 0.409099, 0.407348, 0.406045, 0.404425, 0.402383, 0.39921, 0.397192, 0.395759, 0.392974, 0.392154, 0.392746, 0.391085, 0.388942, 0.388605, 0.3892, 0.388598, 0.390022, 0.390959, 0.390631, 0.38988, 0.387596, 0.387869, 0.387175, 0.386318, 0.386159, 0.3843, 0.385113, 0.385407, 0.385042, 0.384616, 0.383908, 0.383691, 0.383365, 0.384168, 0.383855, 0.382919, 0.382736, 0.385418, 0.387076, 0.388911, 0.389603, 0.390829, 0.39357, 0.392953, 0.393822, 0.393577, 0.395384, 0.39943, 0.398731, 0.399346, 0.401195, 0.401578, 0.403243, 0.404695, 0.404945, 0.403976, 0.403141, 0.404615, 0.405731, 0.405622, 0.404528, 0.403956, 0.403447, 0.404645, 0.406496, 0.408497, 0.409246, 0.412113, 0.412114, 0.413396, 0.414669, 0.415715, 0.41673, 0.415181, 0.418638, 0.419123, 0.420411, 0.420412, 0.421826, 0.423074, 0.423149]\n",
      "saved state to results/tracker_test_XGBoost.pickle\n",
      "Default XGBoost result on CV:\n",
      "\n",
      "loss = 0.387605\n",
      "best_n_estimators = 33\n",
      "params = {'base_score': 0.5, 'colsample_bylevel': 1, 'colsample_bytree': 1, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 3, 'min_child_weight': 1, 'missing': None, 'n_estimators': 100, 'nthread': -1, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': 0, 'subsample': 1, 'objective': 'binary:logistic', 'eval_metric': 'logloss', 'silent': 1}\n",
      "BST  <xgboost.core.Booster object at 0x11ba5e940>\n",
      "RES [0.644516, 0.606161, 0.573153, 0.54463, 0.519761, 0.501423, 0.484038, 0.468841, 0.45592, 0.44409, 0.43248, 0.426242, 0.419107, 0.411681, 0.40565, 0.399041, 0.394999, 0.390879, 0.387021, 0.383102, 0.380658, 0.377994, 0.376217, 0.373896, 0.370822, 0.369634, 0.368687, 0.367719, 0.366378, 0.365256, 0.363518, 0.363299, 0.362318]\n",
      "saved state to results/tracker_test_XGBoost.pickle\n",
      "Default XGBoost result on TEST:\n",
      "\n",
      "loss = 0.362318\n",
      "n_estimators = 33\n",
      "params = {'base_score': 0.5, 'colsample_bylevel': 1, 'colsample_bytree': 1, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 3, 'min_child_weight': 1, 'missing': None, 'n_estimators': 100, 'nthread': -1, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': 0, 'subsample': 1, 'objective': 'binary:logistic', 'eval_metric': 'logloss', 'silent': 1}\n",
      "roc_auc = 0.810917\n",
      "Hyperopt iterations:\n",
      "\n",
      "\n",
      "BST  <xgboost.core.Booster object at 0x10de549e8>\n",
      "RES [0.616971, 0.551756, 0.510391, 0.471179, 0.461405, 0.437833, 0.436337, 0.421347, 0.420325, 0.420588, 0.424498, 0.429782, 0.431014, 0.439775, 0.441874, 0.448959, 0.452035, 0.459435, 0.466531, 0.466926, 0.469851, 0.469276, 0.47696, 0.477761, 0.480012, 0.484281, 0.485871, 0.490279, 0.497538, 0.504224, 0.501345, 0.50421, 0.502742, 0.507009, 0.509088, 0.509861, 0.512015, 0.513875, 0.513922, 0.516481, 0.519555, 0.519197, 0.519438, 0.523082, 0.526423, 0.532355, 0.534664, 0.532172, 0.529229, 0.534638, 0.537975, 0.534929, 0.544072, 0.544422, 0.543713, 0.545953, 0.549316, 0.551874, 0.549439, 0.546743, 0.550506, 0.553019, 0.557091, 0.558985, 0.560298, 0.5618, 0.565881, 0.57328, 0.574224, 0.572566, 0.570559, 0.571842, 0.571793, 0.572386, 0.574606, 0.576903, 0.581495, 0.586561, 0.584689, 0.582919, 0.586759, 0.587222, 0.585333, 0.588844, 0.588528, 0.58735, 0.584539, 0.582576, 0.581755, 0.583774, 0.586684, 0.588767, 0.590884, 0.58828, 0.590469, 0.592215, 0.593836, 0.597457, 0.59586, 0.592149]\n",
      "BST  <xgboost.core.Booster object at 0x12ec461d0>\n",
      "RES [0.602268, 0.534372, 0.484254, 0.450189, 0.440057, 0.413565, 0.413137, 0.402959, 0.402695, 0.405301, 0.400937, 0.409694, 0.410897, 0.420721, 0.416577, 0.420157, 0.427984, 0.435094, 0.439725, 0.446934, 0.45014, 0.464215, 0.46754, 0.482915, 0.480556, 0.486131, 0.487756, 0.492003, 0.49621, 0.500566, 0.507203, 0.507405, 0.504137, 0.511743, 0.51853, 0.521595, 0.525827, 0.534841, 0.540647, 0.546957, 0.544517, 0.540198, 0.529674, 0.533569, 0.528506, 0.529137, 0.528754, 0.529261, 0.526426, 0.532025, 0.533623, 0.534547, 0.533336, 0.538475, 0.534977, 0.537202, 0.537409, 0.542277, 0.546893, 0.558443, 0.557528, 0.559158, 0.556923, 0.556222, 0.561523, 0.556713, 0.557969, 0.560524, 0.564816, 0.565158, 0.562589, 0.5611, 0.558671, 0.557321, 0.553985, 0.55329, 0.554023, 0.554811, 0.552917, 0.551685, 0.558422, 0.561148, 0.559249, 0.56024, 0.558582, 0.563184, 0.563329, 0.564942, 0.563247, 0.564505, 0.568083, 0.568797, 0.572203, 0.571859, 0.576169, 0.57307, 0.576058, 0.573494, 0.573435, 0.576836]\n",
      "[1/2]\teval_time=0.18 sec\tcurrent_logloss=0.411510\tmin_logloss=0.411510\n",
      "BST  <xgboost.core.Booster object at 0x12ec46f60>\n",
      "RES [0.522894, 0.470214, 0.468534, 0.499052, 0.500056, 0.482301, 0.495503, 0.516867, 0.518226, 0.541693, 0.574398, 0.582558, 0.608503, 0.625239, 0.625734, 0.645106, 0.650459, 0.666971, 0.679983, 0.677322, 0.694346, 0.697261, 0.714372, 0.726472, 0.73216, 0.761334, 0.778514, 0.787738, 0.800548, 0.816215, 0.829078, 0.829002, 0.847103, 0.849907, 0.86437, 0.879964, 0.88342, 0.887444, 0.883796, 0.894656, 0.91093, 0.913535, 0.911389, 0.911909, 0.906623, 0.905954, 0.90965, 0.912616, 0.915336, 0.913302, 0.913508, 0.91854, 0.925388, 0.929385, 0.925477, 0.924766, 0.92369, 0.931456, 0.932253, 0.931378, 0.933887, 0.932434, 0.930414, 0.929046, 0.926126, 0.9279, 0.930372, 0.929099, 0.931068, 0.928446, 0.92722, 0.930678, 0.931429, 0.935583, 0.934556, 0.92973, 0.931612, 0.930602, 0.933667, 0.933281, 0.933837, 0.930125, 0.929963, 0.933109, 0.936103, 0.935434, 0.93796, 0.935392, 0.934838, 0.948279, 0.945044, 0.947273, 0.945761, 0.944595, 0.944527, 0.941988, 0.941555, 0.940682, 0.94013, 0.941562]\n",
      "BST  <xgboost.core.Booster object at 0x12ec46d68>\n",
      "RES [0.508701, 0.453008, 0.429534, 0.437144, 0.477707, 0.496604, 0.491958, 0.50328, 0.513102, 0.53199, 0.549481, 0.575815, 0.602175, 0.597062, 0.607295, 0.61374, 0.623868, 0.655522, 0.673415, 0.684483, 0.713814, 0.745667, 0.762416, 0.798945, 0.811088, 0.83642, 0.831831, 0.851754, 0.869468, 0.892755, 0.934742, 0.975891, 0.997119, 1.008731, 1.037052, 1.053553, 1.046065, 1.063012, 1.069288, 1.080812, 1.095818, 1.082706, 1.092118, 1.113529, 1.108164, 1.110449, 1.121975, 1.128837, 1.123465, 1.130664, 1.128693, 1.127931, 1.13627, 1.135611, 1.130322, 1.137254, 1.135518, 1.139051, 1.141664, 1.138921, 1.134492, 1.139187, 1.139789, 1.137067, 1.136472, 1.136841, 1.138517, 1.139992, 1.140275, 1.140126, 1.144193, 1.150977, 1.179275, 1.172937, 1.163568, 1.164813, 1.159828, 1.162106, 1.158934, 1.158228, 1.157002, 1.159145, 1.164582, 1.16452, 1.162966, 1.167184, 1.163567, 1.166616, 1.159822, 1.166204, 1.166216, 1.169146, 1.165897, 1.164892, 1.160331, 1.161297, 1.161853, 1.166596, 1.170459, 1.171636]\n",
      "[2/2]\teval_time=0.18 sec\tcurrent_logloss=0.449034\tmin_logloss=0.411510\n",
      "saved state to results/tracker_test_XGBoost.pickle\n",
      "saved state to results/tracker_test_XGBoost.pickle\n",
      "Tuned XGBoost result on cv:\n",
      "\n",
      "loss = 0.41151000000000004\n",
      "best_n_estimators = 9\n",
      "params = {'alpha': 0, 'colsample_bylevel': 0.7405046763756069, 'colsample_bytree': 0.6151399892026908, 'eta': 0.22398969443165967, 'gamma': 5.745168482871384e-07, 'lambda': 0.019440307789833522, 'max_depth': 10, 'min_child_weight': 0.16853765259109013, 'subsample': 0.6197753137030573, 'objective': 'binary:logistic', 'eval_metric': 'logloss', 'silent': 1}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BST  <xgboost.core.Booster object at 0x11ba5e828>\n",
      "RES [0.585305, 0.509317, 0.469549, 0.435704, 0.412622, 0.398995, 0.389503, 0.384602, 0.381498]\n",
      "saved state to results/tracker_test_XGBoost.pickle\n",
      "Tuned XGBoost result on test:\n",
      "\n",
      "loss = 0.381498\n",
      "n_estimators = 9\n",
      "params = {'alpha': 0, 'colsample_bylevel': 0.7405046763756069, 'colsample_bytree': 0.6151399892026908, 'eta': 0.22398969443165967, 'gamma': 5.745168482871384e-07, 'lambda': 0.019440307789833522, 'max_depth': 10, 'min_child_weight': 0.16853765259109013, 'subsample': 0.6197753137030573, 'objective': 'binary:logistic', 'eval_metric': 'logloss', 'silent': 1}\n",
      "roc_auc = 0.777906\n",
      "saved state to results/tracker_test_XGBoost.pickle\n",
      "~~~~~~~~~~~~~~~~~~~~ LightGBM ~~~~~~~~~~~~~~~~~~~~\n",
      "saved state to results/tracker_test_LightGBM.pickle\n",
      "Default LightGBM result on CV:\n",
      "\n",
      "loss = 0.406009595437\n",
      "best_n_estimators = 29\n",
      "params = {'boosting_type': 'gbdt', 'colsample_bytree': 1, 'drop_rate': 0.1, 'is_unbalance': False, 'learning_rate': 0.1, 'max_bin': 255, 'min_data_in_leaf': 20, 'max_depth': -1, 'max_drop': 50, 'min_child_samples': 10, 'min_child_weight': 5, 'min_split_gain': 0, 'min_sum_hessian_in_leaf': 0.001, 'lambda_l1': 0, 'lambda_l2': 0, 'n_estimators': 10, 'nthread': 4, 'num_threads': 4, 'num_leaves': 31, 'reg_alpha': 0, 'reg_lambda': 0, 'scale_pos_weight': 1, 'seed': 0, 'sigmoid': 1.0, 'skip_drop': 0.5, 'subsample': 1, 'subsample_for_bin': 50000, 'subsample_freq': 1, 'uniform_drop': False, 'xgboost_dart_mode': False, 'objective': 'binary', 'metric': 'binary_logloss', 'bagging_freq': 1, 'verbose': -1}\n",
      "saved state to results/tracker_test_LightGBM.pickle\n",
      "Default LightGBM result on TEST:\n",
      "\n",
      "loss = 0.345204703224\n",
      "n_estimators = 29\n",
      "params = {'boosting_type': 'gbdt', 'colsample_bytree': 1, 'drop_rate': 0.1, 'is_unbalance': False, 'learning_rate': 0.1, 'max_bin': 255, 'min_data_in_leaf': 20, 'max_depth': -1, 'max_drop': 50, 'min_child_samples': 10, 'min_child_weight': 5, 'min_split_gain': 0, 'min_sum_hessian_in_leaf': 0.001, 'lambda_l1': 0, 'lambda_l2': 0, 'n_estimators': 10, 'nthread': 4, 'num_threads': 4, 'num_leaves': 31, 'reg_alpha': 0, 'reg_lambda': 0, 'scale_pos_weight': 1, 'seed': 0, 'sigmoid': 1.0, 'skip_drop': 0.5, 'subsample': 1, 'subsample_for_bin': 50000, 'subsample_freq': 1, 'uniform_drop': False, 'xgboost_dart_mode': False, 'objective': 'binary', 'metric': 'binary_logloss', 'bagging_freq': 1, 'verbose': -1}\n",
      "roc_auc = 0.821449\n",
      "Hyperopt iterations:\n",
      "\n",
      "\n",
      "[1/2]\teval_time=0.09 sec\tcurrent_logloss=0.693147\tmin_logloss=0.693147\n",
      "[2/2]\teval_time=1.08 sec\tcurrent_logloss=0.590885\tmin_logloss=0.590885\n",
      "saved state to results/tracker_test_LightGBM.pickle\n",
      "saved state to results/tracker_test_LightGBM.pickle\n",
      "Tuned LightGBM result on cv:\n",
      "\n",
      "loss = 0.5908853184426857\n",
      "best_n_estimators = 100\n",
      "params = {'bagging_fraction': 0.5292435929542255, 'feature_fraction': 0.9444627024858503, 'lambda_l1': 0, 'lambda_l2': 0, 'learning_rate': 0.0025275717184566064, 'min_data_in_leaf': 10, 'min_sum_hessian_in_leaf': 4.1073662953607967e-07, 'num_leaves': 137, 'objective': 'binary', 'metric': 'binary_logloss', 'bagging_freq': 1, 'verbose': -1, 'max_bin': 255}\n",
      "saved state to results/tracker_test_LightGBM.pickle\n",
      "Tuned LightGBM result on test:\n",
      "\n",
      "loss = 0.583323465799\n",
      "n_estimators = 100\n",
      "params = {'bagging_fraction': 0.5292435929542255, 'feature_fraction': 0.9444627024858503, 'lambda_l1': 0, 'lambda_l2': 0, 'learning_rate': 0.0025275717184566064, 'min_data_in_leaf': 10, 'min_sum_hessian_in_leaf': 4.1073662953607967e-07, 'num_leaves': 137, 'objective': 'binary', 'metric': 'binary_logloss', 'bagging_freq': 1, 'verbose': -1, 'max_bin': 255}\n",
      "roc_auc = 0.806395\n",
      "saved state to results/tracker_test_LightGBM.pickle\n",
      "~~~~~~~~~~~~~~~~~~~~ RandomForestClassifier ~~~~~~~~~~~~~~~~~~~~\n",
      "XYCDataset(X=array([[    0.        ,     0.        ,     0.        , ...,\n",
      "            0.        ,     0.        ,     0.        ],\n",
      "       [ 1021.92480469,    13.87764549,   541.56542969, ...,\n",
      "            0.        ,     0.        ,     0.        ],\n",
      "       [  175.84321594,   131.90345764,   170.24882507, ...,\n",
      "            0.        ,     0.        ,     0.        ],\n",
      "       ..., \n",
      "       [    0.        ,   262.77554321,   221.93186951, ...,\n",
      "            2.41055727,     2.1427176 ,     0.        ],\n",
      "       [    0.        ,   371.41238403,   217.42460632, ...,\n",
      "            1.33919847,     0.        ,     0.        ],\n",
      "       [    0.        ,    87.49720764,   403.44668579, ...,\n",
      "            0.        ,     0.        ,     0.        ]]), y=array([1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1,\n",
      "       1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1,\n",
      "       0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
      "       1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "       1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1]), cat_cols=[])\n",
      "XYCDataset(X=array([[   0.        ,   41.34658432,  222.88896179, ...,    0.        ,\n",
      "           0.        ,    0.        ],\n",
      "       [ 104.20052338,  391.06286621,  108.86438751, ...,    0.        ,\n",
      "           2.1427176 ,    0.        ],\n",
      "       [   0.        ,    0.        ,    0.        , ...,    0.        ,\n",
      "           0.        ,    0.        ],\n",
      "       ..., \n",
      "       [   0.        ,  309.15771484,  488.13595581, ...,    0.        ,\n",
      "           0.        ,    0.        ],\n",
      "       [   0.        ,    0.        ,  197.30007935, ...,    0.        ,\n",
      "           0.        ,    0.        ],\n",
      "       [   0.        ,    0.        ,    0.        , ...,    0.        ,\n",
      "           1.60703814,    0.        ]]), y=array([1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0,\n",
      "       1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
      "       0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
      "       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1,\n",
      "       1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
      "       0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1]), cat_cols=[])\n",
      "{'criterion': 'gini', 'max_depth': 17, 'max_features': 2, 'n_estimators': 14, 'normalize': 0, 'scale': 1}\n",
      "{'max_depth': 1, 'max_features': 4, 'n_estimators': 10, 'criterion': 'gini', 'verbose': 0}\n",
      "XYCDataset(X=array([[   0.        ,   41.34658432,  222.88896179, ...,    0.        ,\n",
      "           0.        ,    0.        ],\n",
      "       [ 104.20052338,  391.06286621,  108.86438751, ...,    0.        ,\n",
      "           2.1427176 ,    0.        ],\n",
      "       [   0.        ,    0.        ,    0.        , ...,    0.        ,\n",
      "           0.        ,    0.        ],\n",
      "       ..., \n",
      "       [   0.        ,  309.15771484,  488.13595581, ...,    0.        ,\n",
      "           0.        ,    0.        ],\n",
      "       [   0.        ,    0.        ,  197.30007935, ...,    0.        ,\n",
      "           0.        ,    0.        ],\n",
      "       [   0.        ,    0.        ,    0.        , ...,    0.        ,\n",
      "           1.60703814,    0.        ]]), y=array([1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0,\n",
      "       1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
      "       0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
      "       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1,\n",
      "       1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
      "       0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1]), cat_cols=[])\n",
      "XYCDataset(X=array([[    0.        ,     0.        ,     0.        , ...,\n",
      "            0.        ,     0.        ,     0.        ],\n",
      "       [ 1021.92480469,    13.87764549,   541.56542969, ...,\n",
      "            0.        ,     0.        ,     0.        ],\n",
      "       [  175.84321594,   131.90345764,   170.24882507, ...,\n",
      "            0.        ,     0.        ,     0.        ],\n",
      "       ..., \n",
      "       [    0.        ,   262.77554321,   221.93186951, ...,\n",
      "            2.41055727,     2.1427176 ,     0.        ],\n",
      "       [    0.        ,   371.41238403,   217.42460632, ...,\n",
      "            1.33919847,     0.        ,     0.        ],\n",
      "       [    0.        ,    87.49720764,   403.44668579, ...,\n",
      "            0.        ,     0.        ,     0.        ]]), y=array([1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1,\n",
      "       1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1,\n",
      "       0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
      "       1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "       1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1]), cat_cols=[])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'gini', 'max_depth': 8, 'max_features': 4, 'n_estimators': 8, 'normalize': 1, 'scale': 1}\n",
      "{'max_depth': 1, 'max_features': 4, 'n_estimators': 10, 'criterion': 'gini', 'verbose': 0}\n",
      "saved state to results/tracker_test_RandomForestClassifier.pickle\n",
      "Default RandomForestClassifier result on CV:\n",
      "\n",
      "loss = 0.709934978007\n",
      "best_n_estimators = 59\n",
      "params = {'max_depth': 1, 'max_features': 4, 'n_estimators': 10, 'criterion': 'gini', 'verbose': 0}\n",
      "XYCDataset(X=array([[    0.        ,     0.        ,     0.        , ...,\n",
      "            0.        ,     0.        ,     0.        ],\n",
      "       [    0.        ,    41.34658432,   222.88896179, ...,\n",
      "            0.        ,     0.        ,     0.        ],\n",
      "       [ 1021.92480469,    13.87764549,   541.56542969, ...,\n",
      "            0.        ,     0.        ,     0.        ],\n",
      "       ..., \n",
      "       [    0.        ,   309.15771484,   488.13595581, ...,\n",
      "            0.        ,     0.        ,     0.        ],\n",
      "       [    0.        ,     0.        ,   197.30007935, ...,\n",
      "            0.        ,     0.        ,     0.        ],\n",
      "       [    0.        ,     0.        ,     0.        , ...,\n",
      "            0.        ,     1.60703814,     0.        ]]), y=array([1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0,\n",
      "       1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
      "       1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1,\n",
      "       1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0,\n",
      "       1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
      "       1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
      "       1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1,\n",
      "       0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1]), cat_cols=[])\n",
      "XYCDataset(X=array([[    0.        ,    69.73749542,   200.5402832 , ...,\n",
      "            0.        ,     0.        ,     0.        ],\n",
      "       [  -25.62042427,   -67.51338959,   381.62976074, ...,\n",
      "            0.        ,     0.        ,     0.        ],\n",
      "       [  588.79718018,   178.09083557,   269.97335815, ...,\n",
      "            9.64222908,     3.21407628,     0.        ],\n",
      "       ..., \n",
      "       [  756.94128418,  1195.62878418,   290.07937622, ...,\n",
      "            0.        ,     0.        ,     0.        ],\n",
      "       [  -40.32682037,   364.51065063,   225.75440979, ...,\n",
      "            0.        ,     0.        ,     0.        ],\n",
      "       [    0.        ,     0.        ,     0.        , ...,\n",
      "            0.        ,     0.        ,     0.        ]]), y=array([1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
      "       1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0,\n",
      "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1,\n",
      "       1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1,\n",
      "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
      "       1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1,\n",
      "       1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "       1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
      "       1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0,\n",
      "       0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1,\n",
      "       1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1]), cat_cols=[])\n",
      "{'criterion': 'gini', 'max_depth': 19, 'max_features': 1, 'n_estimators': 12, 'normalize': 0, 'scale': 1}\n",
      "{'max_depth': 1, 'max_features': 4, 'n_estimators': 10, 'criterion': 'gini', 'verbose': 0}\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'XYCDataset' object has no attribute 'get_label'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-edc3882e5a3b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m                                                   \u001b[0mdefault_cv_result\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'params'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                                                   \u001b[0mdefault_cv_result\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'best_n_estimators'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m                                                   custom_metric = {'roc_auc': roc_auc_score})\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mtrackers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdefault_test_result\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/py3/lib/python3.6/site-packages/modelgym-0.1.2.1-py3.6.egg/modelgym/trainer.py\u001b[0m in \u001b[0;36mfit_eval\u001b[0;34m(self, model, dtrain, dtest, params, n_estimators, custom_metric)\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_dtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# TODO: why 2 args?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmetric_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric_func\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcustom_metric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m                 \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetric_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_dtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# TODO weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m                 \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmetric_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'XYCDataset' object has no attribute 'get_label'"
     ]
    }
   ],
   "source": [
    "for model_id, model_class in CANDIDATES.items():\n",
    "    model = model_class(TASK_CLASSIFICATION)\n",
    "    print (\"~\"*20, model.get_name(), \"~\"*20)\n",
    "    trackers[model_id] = tracker_factory(model_name=model.get_name())\n",
    "    if LOAD_CACHE:\n",
    "        default_cv_result[model_id], default_test_result[model_id], tuned_cv_result[model_id], tuned_test_result[model_id], trials[model_id] = \\\n",
    "            trackers[model_id].load_state(as_list=True)\n",
    "    \n",
    "    \n",
    "    if default_cv_result[model_id] is None:\n",
    "        default_cv_result[model_id] = trainer.crossval_fit_eval(model, cv_pairs)\n",
    "        trackers[model_id].save_state(default_cv=default_cv_result[model_id])\n",
    "    trainer.print_result(default_cv_result[model_id], 'Default {} result on CV'.format(model.get_name()))\n",
    "\n",
    "    if default_test_result[model_id] is None:\n",
    "        default_test_result[model_id] = trainer.fit_eval(model, dtrain, dtest,\n",
    "                                                  default_cv_result[model_id]['params'],\n",
    "                                                  default_cv_result[model_id]['best_n_estimators'],\n",
    "                                                  custom_metric = {'roc_auc': roc_auc_score})\n",
    "        trackers[model_id].save_state(default_test=default_test_result[model_id])\n",
    "\n",
    "    trainer.print_result(default_test_result[model_id], 'Default {} result on TEST'.format(model.get_name()), extra_keys=['roc_auc'])\n",
    "\n",
    "        \n",
    "    if tuned_cv_result[model_id] is None:\n",
    "        print('Hyperopt iterations:\\n\\n')\n",
    "        tuned_cv_result[model_id] = trainer.crossval_optimize_params(model, cv_pairs,  algo_name=OPTIMIZER, \n",
    "                                                           trials=trials[model_id], tracker=trackers[model_id])\n",
    "        trackers[model_id].save_state(tuned_cv=tuned_cv_result[model_id])\n",
    "    trainer.print_result(tuned_cv_result[model_id], 'Tuned {} result on cv'.format(model.get_name()))\n",
    "\n",
    "    if tuned_test_result[model_id] is None:\n",
    "        tuned_test_result[model_id] = trainer.fit_eval(model, dtrain, dtest,\n",
    "                                            tuned_cv_result[model_id]['params'],\n",
    "                                            tuned_cv_result[model_id]['best_n_estimators'],\n",
    "                                            custom_metric = {'roc_auc': roc_auc_score})\n",
    "        trackers[model_id].save_state(tuned_test=tuned_test_result[model_id])\n",
    "    trainer.print_result(tuned_test_result[model_id], 'Tuned {} result on test'.format(model.get_name()), extra_keys=['roc_auc'])\n",
    "\n",
    "    trackers[model_id].save_state(default_cv=default_cv_result[model_id], default_test=default_test_result[model_id], \n",
    "                               tuned_cv=tuned_cv_result[model_id], tuned_test=tuned_test_result[model_id], trials=trials[model_id])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "metric, mes_min = 'roc_auc', False\n",
    "full_results = {}\n",
    "for i in CANDIDATES.keys():\n",
    "    if i in trackers:\n",
    "        tracker = trackers[i]\n",
    "    else:\n",
    "        tracker = tracker_factory(model_name=i)\n",
    "        tracker.load_state()\n",
    "    full_results.update({i:{'tuned': tracker.state['tuned_test'], 'default': tracker.state['default_test']}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_metric_results(full_results, index, metric, is_min_better=True):\n",
    "    test_results_list = []\n",
    "    for i in index:\n",
    "        test_results_list.append([full_results[i]['default'][metric], full_results[i]['tuned'][metric]])\n",
    "        \n",
    "    test_results = np.array(test_results_list)\n",
    "    if is_min_better:\n",
    "        baseline = test_results.min()\n",
    "    else:\n",
    "        baseline = test_results.max()\n",
    "    diff = 100 * test_results / baseline - 100\n",
    "    test_results_formatted = [['{:.6f} ({:+.2f}%)'.format(test_results[i, j], diff[i, j]) for j in range(2)] for i in range(len(index))]\n",
    "\n",
    "    print (pd.DataFrame(test_results_formatted, columns=['default', 'tuned'], index=index))\n",
    "    \n",
    "    full_names = [\" \".join(i) for i in itertools.product(index, ['default', 'tuned'])]\n",
    "\n",
    "    named_results = zip(full_names, test_results.flatten())\n",
    "\n",
    "    sorted_results = sorted(named_results, key=lambda x: x[1], reverse=not is_min_better)\n",
    "    xticks = ['%s\\n%.5f' % (name, loss) for name, loss in sorted_results]\n",
    "\n",
    "    pyplot.figure(figsize=(20, 7))\n",
    "    pyplot.scatter(range(len(full_names)), list(zip(*sorted_results))[1], s=150)\n",
    "    pyplot.xticks(range(len(full_names)), xticks, fontsize=15)\n",
    "    pyplot.yticks(fontsize=12)\n",
    "    pyplot.title('Comparison', fontsize=20)\n",
    "    pyplot.ylabel(metric, fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%pylab inline --no-import-all\n",
    "metric, is_min_better = 'roc_auc', False\n",
    "plot_metric_results(full_results, CANDIDATES.keys(), metric, is_min_better=is_min_better)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
