{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#from modelgym import model\n",
    "import functools\n",
    "import modelgym\n",
    "from modelgym.util import TASK_CLASSIFICATION\n",
    "from modelgym.trainer import Trainer\n",
    "from modelgym.tracker import ProgressTrackerFile, ProgressTrackerMongo\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from hyperopt.mongoexp import MongoTrials\n",
    "from modelgym.util import split_and_preprocess\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using File as backend for tracking\n",
      "Running experiment cofiguration: test\n"
     ]
    }
   ],
   "source": [
    "########### NROWS, N_ESTIMATORS, N_PROBES, TEST_SIZE, N_CV_SPLITS, OPTIMIZER\n",
    "config_tuple = {\n",
    "    'test': (1000, 100,  2, 0.5, 2, 'random'),\n",
    "    'pror': (None, 1000, 100, 0.5, 2, 'random'), # production with random hyperopt suggestor\n",
    "    'prot': (None, 1000, 100, 0.5, 2, 'tpe'),    # production with tpe hyperopt suggestor\n",
    "    'demi': (10000, 100, 5, 0.5, 2, 'random')\n",
    "}\n",
    "CONFIG = 'test' if 'EXP_CONFIG' not in os.environ else os.environ['EXP_CONFIG']\n",
    "NROWS, N_ESTIMATORS, N_PROBES, TEST_SIZE, N_CV_SPLITS, OPTIMIZER = config_tuple[CONFIG]\n",
    "CANDIDATES = OrderedDict([\n",
    "    ('XGBoost', modelgym.XGBModel), \n",
    "    ('LightGBM', modelgym.LGBModel),\n",
    "    ('RandomForestClassifier',modelgym.RFModel)\n",
    "])\n",
    "RESULTS_DIR = \"results\"\n",
    "LOAD_CACHE = False\n",
    "if 'MONGO_PORT_27017_TCP_ADDR' in os.environ:\n",
    "    mongo_host = os.environ['MONGO_PORT_27017_TCP_ADDR'] if 'MONGO_PORT_27017_TCP_ADDR' in os.environ else 'cern-mc01h'\n",
    "    mongo_port = int(os.environ['MONGO_PORT_27017_TCP_PORT']) if 'MONGO_PORT_27017_TCP_PORT' in os.environ else 27017\n",
    "    mongo_db = os.environ['MONGO_DB'] if 'MONGO_DB' in os.environ else 'trials'\n",
    "    tracker_factory = functools.partial(ProgressTrackerMongo, mongo_host, mongo_port, mongo_db, config_key=CONFIG)\n",
    "    print (\"Using Mongo as backend for tracking\")\n",
    "else:\n",
    "    tracker_factory = functools.partial(ProgressTrackerFile, RESULTS_DIR, config_key=CONFIG)\n",
    "    print (\"Using File as backend for tracking\")\n",
    "\n",
    "print (\"Running experiment cofiguration:\", CONFIG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download & read data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 266224\n",
      "-rw-r--r--  1 macbook  staff  136304022 Aug 11 14:40 XY2d.pickle\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "if [ ! -d data ] ; then \n",
    "    mkdir data \n",
    "    cd data\n",
    "    curl https://cernbox.cern.ch/index.php/s/N1dpSAPgl30szYM/download | gunzip -c > XY2d.pickle\n",
    "    cd ..\n",
    "fi\n",
    "ls -l data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_data(fname, nrows=None, shuffle=True):\n",
    "    with open(fname,'rb') as fh:\n",
    "        X, y = pickle.load(fh,encoding='bytes')\n",
    "    index = np.arange(X.shape[0])\n",
    "    if nrows is None:\n",
    "        nrows = X.shape[0]\n",
    "    weights = np.ones(nrows) # uh, well...\n",
    "    if shuffle:\n",
    "        index_perm = np.random.permutation(index)\n",
    "    else:\n",
    "        index_perm = index\n",
    "    return X[index_perm[:nrows]], y[index_perm[:nrows]], weights\n",
    "\n",
    "\n",
    "X, y, weights = read_data(\"data/XY2d.pickle\", nrows=NROWS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, w_train, w_test = train_test_split(X, y, weights, test_size=TEST_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv_pairs, (dtrain, dtest) = split_and_preprocess(X_train.copy(), y_train, \n",
    "                                                X_test.copy(), y_test, \n",
    "                                                cat_cols=[], n_splits=N_CV_SPLITS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run them all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trackers = {}\n",
    "def init_keys_dict():\n",
    "    return dict([(k, None) for k in CANDIDATES.keys()])\n",
    "default_cv_result = init_keys_dict()\n",
    "tuned_cv_result = init_keys_dict()\n",
    "default_test_result = init_keys_dict()\n",
    "tuned_test_result = init_keys_dict()\n",
    "trials = init_keys_dict()\n",
    "trainer = Trainer(hyperopt_evals=N_PROBES, n_estimators=N_ESTIMATORS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~~ XGBoost ~~~~~~~~~~~~~~~~~~~~\n",
      "BST  <xgboost.core.Booster object at 0x10f2d2898>\n",
      "RES [0.639015, 0.59697, 0.560292, 0.530095, 0.504147, 0.483146, 0.466197, 0.45078, 0.43739, 0.425455, 0.41608, 0.4089, 0.403945, 0.398489, 0.393422, 0.39033, 0.389786, 0.386504, 0.385315, 0.384363, 0.381574, 0.381022, 0.378459, 0.377447, 0.37765, 0.378634, 0.378764, 0.381958, 0.383001, 0.381755, 0.38291, 0.383754, 0.388388, 0.389157, 0.390195, 0.389849, 0.391495, 0.392524, 0.394254, 0.395603, 0.395377, 0.395017, 0.39507, 0.399614, 0.399553, 0.401836, 0.401376, 0.40281, 0.404191, 0.405153, 0.406114, 0.407608, 0.408868, 0.410935, 0.410542, 0.412306, 0.413515, 0.41356, 0.413748, 0.41598, 0.415033, 0.416508, 0.415067, 0.416609, 0.415681, 0.415448, 0.415255, 0.416849, 0.417567, 0.416777, 0.418229, 0.416653, 0.41775, 0.418928, 0.419566, 0.420083, 0.418683, 0.415769, 0.41768, 0.419547, 0.419845, 0.421107, 0.421911, 0.423609, 0.424732, 0.425194, 0.425876, 0.425704, 0.426431, 0.426193, 0.425691, 0.426885, 0.428656, 0.428496, 0.429828, 0.431162, 0.43189, 0.431611, 0.431856, 0.432428]\n",
      "BST  <xgboost.core.Booster object at 0x10f2d2908>\n",
      "RES [0.638741, 0.597913, 0.563426, 0.53732, 0.513845, 0.494319, 0.476401, 0.461915, 0.451003, 0.44146, 0.430345, 0.424188, 0.417933, 0.413317, 0.407137, 0.402378, 0.399287, 0.400214, 0.397677, 0.396661, 0.395318, 0.395782, 0.396887, 0.394787, 0.393776, 0.393147, 0.393175, 0.394283, 0.393227, 0.391121, 0.39069, 0.391374, 0.390989, 0.389882, 0.392089, 0.393744, 0.39481, 0.395132, 0.394093, 0.394578, 0.394662, 0.396693, 0.398277, 0.398162, 0.397649, 0.398276, 0.399077, 0.399568, 0.401888, 0.402231, 0.402661, 0.403776, 0.404776, 0.405532, 0.407377, 0.406434, 0.405038, 0.407335, 0.409514, 0.410317, 0.410184, 0.410338, 0.410201, 0.412666, 0.413233, 0.413961, 0.413451, 0.415401, 0.416354, 0.418739, 0.419654, 0.420382, 0.419941, 0.421931, 0.422979, 0.422693, 0.422183, 0.421701, 0.421873, 0.422615, 0.422884, 0.423917, 0.424646, 0.424622, 0.42608, 0.427044, 0.427923, 0.427658, 0.428333, 0.428121, 0.428894, 0.428495, 0.428435, 0.430145, 0.43126, 0.431462, 0.43277, 0.433777, 0.435273, 0.435083]\n",
      "saved state to results/tracker_test_XGBoost.pickle\n",
      "Default XGBoost result on CV:\n",
      "\n",
      "loss = 0.385713\n",
      "best_n_estimators = 25\n",
      "params = {'base_score': 0.5, 'colsample_bylevel': 1, 'colsample_bytree': 1, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 3, 'min_child_weight': 1, 'missing': None, 'n_estimators': 100, 'nthread': -1, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': 0, 'subsample': 1, 'objective': 'binary:logistic', 'eval_metric': 'logloss', 'silent': 1}\n",
      "BST  <xgboost.core.Booster object at 0x10f2d29b0>\n",
      "RES [0.640282, 0.599825, 0.565449, 0.538431, 0.513908, 0.493557, 0.477342, 0.465017, 0.451294, 0.441492, 0.430197, 0.423686, 0.415569, 0.409808, 0.403424, 0.400107, 0.39267, 0.388159, 0.383024, 0.37978, 0.377603, 0.374255, 0.374078, 0.372558, 0.371663]\n",
      "saved state to results/tracker_test_XGBoost.pickle\n",
      "Default XGBoost result on TEST:\n",
      "\n",
      "loss = 0.371663\n",
      "n_estimators = 25\n",
      "params = {'base_score': 0.5, 'colsample_bylevel': 1, 'colsample_bytree': 1, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 3, 'min_child_weight': 1, 'missing': None, 'n_estimators': 100, 'nthread': -1, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': 0, 'subsample': 1, 'objective': 'binary:logistic', 'eval_metric': 'logloss', 'silent': 1}\n",
      "roc_auc = 0.835934\n",
      "Hyperopt iterations:\n",
      "\n",
      "\n",
      "BST  <xgboost.core.Booster object at 0x10f2c0b38>\n",
      "RES [0.57349, 0.509801, 0.452826, 0.419656, 0.400634, 0.382469, 0.367721, 0.36342, 0.359706, 0.362414, 0.364948, 0.36583, 0.375561, 0.383981, 0.390565, 0.406291, 0.412221, 0.427247, 0.428589, 0.433458, 0.442309, 0.448261, 0.448852, 0.455358, 0.45651, 0.458521, 0.461608, 0.470248, 0.473, 0.470083, 0.472938, 0.485382, 0.498745, 0.495246, 0.494058, 0.490441, 0.502923, 0.501767, 0.506117, 0.509724, 0.504811, 0.509508, 0.519564, 0.519659, 0.513373, 0.519192, 0.514338, 0.511604, 0.508265, 0.512263, 0.50953, 0.514907, 0.518141, 0.523061, 0.526349, 0.529555, 0.525544, 0.527578, 0.533805, 0.537083, 0.539751, 0.53959, 0.53575, 0.535341, 0.533966, 0.53398, 0.532835, 0.535618, 0.531343, 0.530094, 0.53398, 0.531867, 0.53714, 0.530414, 0.527894, 0.52877, 0.530798, 0.529951, 0.531197, 0.533009, 0.530288, 0.527419, 0.528316, 0.520889, 0.523236, 0.52487, 0.532819, 0.532919, 0.54081, 0.538845, 0.536215, 0.533121, 0.530556, 0.529197, 0.53669, 0.533475, 0.538068, 0.538339, 0.541549, 0.536647]\n",
      "BST  <xgboost.core.Booster object at 0x1026a9828>\n",
      "RES [0.590056, 0.520809, 0.490546, 0.448495, 0.417114, 0.402399, 0.40748, 0.394701, 0.397191, 0.398308, 0.402818, 0.407563, 0.4084, 0.408465, 0.419487, 0.425018, 0.430193, 0.443937, 0.443018, 0.45249, 0.459873, 0.471671, 0.483093, 0.49238, 0.503578, 0.511285, 0.51676, 0.523713, 0.524782, 0.525238, 0.518969, 0.527224, 0.527268, 0.535891, 0.535526, 0.546216, 0.548457, 0.54776, 0.539963, 0.544325, 0.543726, 0.545212, 0.543052, 0.548069, 0.550581, 0.548408, 0.551937, 0.551254, 0.552902, 0.552554, 0.556776, 0.564936, 0.562041, 0.56342, 0.564331, 0.564429, 0.567014, 0.572273, 0.566567, 0.572955, 0.570532, 0.57082, 0.571451, 0.567973, 0.565994, 0.566291, 0.56509, 0.570913, 0.568072, 0.566008, 0.571312, 0.571363, 0.567854, 0.567562, 0.572881, 0.576901, 0.576826, 0.574022, 0.571273, 0.576096, 0.581352, 0.577073, 0.575051, 0.571799, 0.574679, 0.577497, 0.577184, 0.584512, 0.585727, 0.583386, 0.581359, 0.581517, 0.577073, 0.578383, 0.579768, 0.581753, 0.578826, 0.581103, 0.583644, 0.586505]\n",
      "[1/2]\teval_time=0.19 sec\tcurrent_logloss=0.378449\tmin_logloss=0.378449\n",
      "BST  <xgboost.core.Booster object at 0x10f2c0b38>\n",
      "RES [0.514571, 0.419803, 0.40102, 0.391549, 0.378404, 0.371935, 0.390813, 0.419719, 0.4348, 0.456698, 0.480051, 0.479511, 0.493573, 0.516232, 0.547186, 0.564893, 0.610098, 0.630532, 0.640752, 0.64773, 0.67042, 0.692038, 0.703062, 0.713704, 0.745772, 0.767819, 0.787521, 0.774694, 0.795189, 0.808708, 0.833614, 0.82638, 0.851187, 0.867323, 0.86683, 0.885497, 0.906178, 0.938914, 0.927708, 0.933267, 0.944153, 0.937921, 0.930287, 0.92566, 0.929174, 0.929827, 0.928682, 0.942895, 0.938587, 0.936718, 0.934919, 0.935959, 0.934864, 0.932782, 0.934137, 0.943509, 0.941441, 0.9367, 0.940708, 0.936336, 0.936891, 0.934116, 0.931851, 0.943749, 0.941367, 0.961466, 0.957265, 0.95691, 0.955495, 0.957071, 0.955864, 0.956383, 0.956509, 0.956349, 0.958376, 0.960638, 0.957689, 0.955007, 0.958973, 0.95895, 0.958267, 0.961602, 0.960851, 0.961057, 0.96136, 0.961195, 0.965843, 0.958856, 0.957719, 0.9583, 0.958022, 0.959241, 0.960911, 0.95902, 0.960281, 0.961639, 0.96127, 0.967377, 0.965599, 0.962997]\n",
      "BST  <xgboost.core.Booster object at 0x122496240>\n",
      "RES [0.525689, 0.440459, 0.401264, 0.395601, 0.399406, 0.404422, 0.419602, 0.44041, 0.45496, 0.476371, 0.494115, 0.517657, 0.540809, 0.555232, 0.590485, 0.602483, 0.627145, 0.643816, 0.641212, 0.64307, 0.669534, 0.681021, 0.704609, 0.716395, 0.729635, 0.750017, 0.788427, 0.809147, 0.824746, 0.844981, 0.848918, 0.855843, 0.865541, 0.876323, 0.895716, 0.910803, 0.898385, 0.892923, 0.893185, 0.895466, 0.888238, 0.905205, 0.910105, 0.910752, 0.916761, 0.914056, 0.912779, 0.914733, 0.921475, 0.927432, 0.924949, 0.934098, 0.934571, 0.936993, 0.934704, 0.937924, 0.944369, 0.959953, 0.955849, 0.953647, 0.955656, 0.954742, 0.961932, 0.962258, 0.959763, 0.957989, 0.957811, 0.958776, 0.955418, 0.954795, 0.951247, 0.952661, 0.953078, 0.954661, 0.95491, 0.953839, 0.953581, 0.954567, 0.955418, 0.955834, 0.955897, 0.951554, 0.957164, 0.958417, 0.956962, 0.95625, 0.953614, 0.953619, 0.955062, 0.954399, 0.956819, 0.95809, 0.956815, 0.954627, 0.954819, 0.952988, 0.95461, 0.952278, 0.954273, 0.95403]\n",
      "[2/2]\teval_time=0.16 sec\tcurrent_logloss=0.388178\tmin_logloss=0.378449\n",
      "saved state to results/tracker_test_XGBoost.pickle\n",
      "saved state to results/tracker_test_XGBoost.pickle\n",
      "Tuned XGBoost result on cv:\n",
      "\n",
      "loss = 0.3784485\n",
      "best_n_estimators = 9\n",
      "params = {'alpha': 0, 'colsample_bylevel': 0.7405046763756069, 'colsample_bytree': 0.6151399892026908, 'eta': 0.22398969443165967, 'gamma': 5.745168482871384e-07, 'lambda': 0.019440307789833522, 'max_depth': 10, 'min_child_weight': 0.16853765259109013, 'subsample': 0.6197753137030573, 'objective': 'binary:logistic', 'eval_metric': 'logloss', 'silent': 1}\n",
      "BST  <xgboost.core.Booster object at 0x1026a9828>\n",
      "RES [0.596447, 0.531698, 0.467789, 0.429137, 0.402149, 0.387569, 0.372794, 0.362225, 0.360539]\n",
      "saved state to results/tracker_test_XGBoost.pickle\n",
      "Tuned XGBoost result on test:\n",
      "\n",
      "loss = 0.360539\n",
      "n_estimators = 9\n",
      "params = {'alpha': 0, 'colsample_bylevel': 0.7405046763756069, 'colsample_bytree': 0.6151399892026908, 'eta': 0.22398969443165967, 'gamma': 5.745168482871384e-07, 'lambda': 0.019440307789833522, 'max_depth': 10, 'min_child_weight': 0.16853765259109013, 'subsample': 0.6197753137030573, 'objective': 'binary:logistic', 'eval_metric': 'logloss', 'silent': 1}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc_auc = 0.821401\n",
      "saved state to results/tracker_test_XGBoost.pickle\n",
      "~~~~~~~~~~~~~~~~~~~~ LightGBM ~~~~~~~~~~~~~~~~~~~~\n",
      "saved state to results/tracker_test_LightGBM.pickle\n",
      "Default LightGBM result on CV:\n",
      "\n",
      "loss = 0.372338232802\n",
      "best_n_estimators = 33\n",
      "params = {'boosting_type': 'gbdt', 'colsample_bytree': 1, 'drop_rate': 0.1, 'is_unbalance': False, 'learning_rate': 0.1, 'max_bin': 255, 'min_data_in_leaf': 20, 'max_depth': -1, 'max_drop': 50, 'min_child_samples': 10, 'min_child_weight': 5, 'min_split_gain': 0, 'min_sum_hessian_in_leaf': 0.001, 'lambda_l1': 0, 'lambda_l2': 0, 'n_estimators': 10, 'nthread': 4, 'num_threads': 4, 'num_leaves': 31, 'reg_alpha': 0, 'reg_lambda': 0, 'scale_pos_weight': 1, 'seed': 0, 'sigmoid': 1.0, 'skip_drop': 0.5, 'subsample': 1, 'subsample_for_bin': 50000, 'subsample_freq': 1, 'uniform_drop': False, 'xgboost_dart_mode': False, 'objective': 'binary', 'metric': 'binary_logloss', 'bagging_freq': 1, 'verbose': -1}\n",
      "saved state to results/tracker_test_LightGBM.pickle\n",
      "Default LightGBM result on TEST:\n",
      "\n",
      "loss = 0.361585743454\n",
      "n_estimators = 33\n",
      "params = {'boosting_type': 'gbdt', 'colsample_bytree': 1, 'drop_rate': 0.1, 'is_unbalance': False, 'learning_rate': 0.1, 'max_bin': 255, 'min_data_in_leaf': 20, 'max_depth': -1, 'max_drop': 50, 'min_child_samples': 10, 'min_child_weight': 5, 'min_split_gain': 0, 'min_sum_hessian_in_leaf': 0.001, 'lambda_l1': 0, 'lambda_l2': 0, 'n_estimators': 10, 'nthread': 4, 'num_threads': 4, 'num_leaves': 31, 'reg_alpha': 0, 'reg_lambda': 0, 'scale_pos_weight': 1, 'seed': 0, 'sigmoid': 1.0, 'skip_drop': 0.5, 'subsample': 1, 'subsample_for_bin': 50000, 'subsample_freq': 1, 'uniform_drop': False, 'xgboost_dart_mode': False, 'objective': 'binary', 'metric': 'binary_logloss', 'bagging_freq': 1, 'verbose': -1}\n",
      "roc_auc = 0.818613\n",
      "Hyperopt iterations:\n",
      "\n",
      "\n",
      "[1/2]\teval_time=0.10 sec\tcurrent_logloss=0.693147\tmin_logloss=0.693147\n",
      "[2/2]\teval_time=1.21 sec\tcurrent_logloss=0.581411\tmin_logloss=0.581411\n",
      "saved state to results/tracker_test_LightGBM.pickle\n",
      "saved state to results/tracker_test_LightGBM.pickle\n",
      "Tuned LightGBM result on cv:\n",
      "\n",
      "loss = 0.5814106286094755\n",
      "best_n_estimators = 100\n",
      "params = {'bagging_fraction': 0.5292435929542255, 'feature_fraction': 0.9444627024858503, 'lambda_l1': 0, 'lambda_l2': 0, 'learning_rate': 0.0025275717184566064, 'min_data_in_leaf': 10, 'min_sum_hessian_in_leaf': 4.1073662953607967e-07, 'num_leaves': 137, 'objective': 'binary', 'metric': 'binary_logloss', 'bagging_freq': 1, 'verbose': -1, 'max_bin': 255}\n",
      "saved state to results/tracker_test_LightGBM.pickle\n",
      "Tuned LightGBM result on test:\n",
      "\n",
      "loss = 0.580688376175\n",
      "n_estimators = 100\n",
      "params = {'bagging_fraction': 0.5292435929542255, 'feature_fraction': 0.9444627024858503, 'lambda_l1': 0, 'lambda_l2': 0, 'learning_rate': 0.0025275717184566064, 'min_data_in_leaf': 10, 'min_sum_hessian_in_leaf': 4.1073662953607967e-07, 'num_leaves': 137, 'objective': 'binary', 'metric': 'binary_logloss', 'bagging_freq': 1, 'verbose': -1, 'max_bin': 255}\n",
      "roc_auc = 0.835284\n",
      "saved state to results/tracker_test_LightGBM.pickle\n",
      "~~~~~~~~~~~~~~~~~~~~ RandomForestClassifier ~~~~~~~~~~~~~~~~~~~~\n",
      "{'criterion': 'gini', 'max_depth': 18, 'max_features': 2, 'n_estimators': 10, 'normalize': 0, 'scale': 0}\n",
      "{'max_depth': 1, 'max_features': 4, 'n_estimators': 10, 'criterion': 'gini', 'verbose': 0}\n",
      "[0.8560782036391793, 0.86004645760743326, 0.7999419279907084, 0.85598141695702668, 0.84814169570267117, 0.86004645760743326, 0.86004645760743326, 0.86004645760743326, 0.86004645760743326, 0.85210994967092535, 0.83188153310104518, 0.86004645760743326, 0.86004645760743326, 0.8319783197831977, 0.82404181184668979, 0.82026713124274098, 0.85617499032133182, 0.86004645760743326, 0.8283004258614014, 0.86004645760743326, 0.86014324428958577, 0.83584978706929924, 0.67605497483546273, 0.8319783197831977, 0.85617499032133182, 0.85598141695702668, 0.83584978706929924, 0.84417344173441722, 0.84407665505226481, 0.84794812233836625, 0.86004645760743326, 0.8319783197831977, 0.85201316298877272, 0.81213704994192792, 0.84794812233836625, 0.86004645760743326, 0.86014324428958577, 0.83604336043360428, 0.86004645760743326, 0.83207510646535032, 0.86004645760743326, 0.86014324428958577, 0.84010840108401086, 0.84804490902051877, 0.82820363917924888, 0.83217189314750284, 0.8560782036391793, 0.87204800619434764, 0.84010840108401075, 0.85210994967092535, 0.86004645760743326, 0.82791327913279122, 0.85181958962446769, 0.84010840108401086, 0.71564072783584987, 0.86807975222609368, 0.8439798683701123, 0.84417344173441722, 0.8560782036391793, 0.86004645760743326, 0.86004645760743326, 0.84407665505226481, 0.84775454897406111, 0.84436701509872236, 0.79607046070460719, 0.85617499032133182, 0.86411149825783973, 0.86004645760743326, 0.8519163763066202, 0.85210994967092535, 0.85210994967092535, 0.85201316298877272, 0.82384823848238486, 0.86004645760743326, 0.85201316298877272, 0.82384823848238486, 0.73170731707317083, 0.85598141695702668, 0.86004645760743326, 0.86004645760743326, 0.86004645760743326, 0.85598141695702668, 0.85210994967092535, 0.84407665505226481, 0.84010840108401086, 0.84814169570267139, 0.85210994967092535, 0.81610530391018188, 0.84427022841656985, 0.84010840108401086, 0.84417344173441722, 0.83614014711575679, 0.86004645760743326, 0.84010840108401075, 0.85201316298877272, 0.8041037553232675, 0.86004645760743326, 0.78029423151374366, 0.70760743321718922, 0.83623693379790931, 0.86004645760743326, 0.86004645760743326, 0.8560782036391793, 0.8519163763066202, 0.8439798683701123, 0.78435927216415013, 0.83584978706929924, 0.86411149825783973, 0.86411149825783973, 0.85210994967092535, 0.85220673635307786, 0.85201316298877272, 0.86411149825783973, 0.84814169570267139, 0.8560782036391793, 0.85210994967092535, 0.85598141695702668, 0.84436701509872236, 0.86411149825783973, 0.84794812233836625, 0.86004645760743326, 0.86014324428958577, 0.82007355787843583, 0.83178474641889277, 0.85210994967092535, 0.86004645760743326, 0.86014324428958577, 0.84417344173441722, 0.69986449864498645, 0.83188153310104518, 0.85220673635307775, 0.76374370886566012, 0.86004645760743326, 0.86004645760743326, 0.86391792489353458, 0.80816879597367397, 0.84010840108401075, 0.85617499032133182, 0.84417344173441744, 0.8560782036391793, 0.86014324428958577, 0.85220673635307775, 0.86014324428958577, 0.8560782036391793, 0.86411149825783973, 0.84804490902051877, 0.81184668989547026, 0.84010840108401075, 0.82384823848238486, 0.85201316298877272, 0.84794812233836625, 0.84407665505226481, 0.8560782036391793, 0.8560782036391793, 0.8439798683701123, 0.86411149825783973, 0.79655439411536966, 0.83991482771970583, 0.8560782036391793, 0.85598141695702668, 0.86004645760743326, 0.8560782036391793, 0.85201316298877272, 0.84001161440185823, 0.8560782036391793, 0.85617499032133182, 0.86004645760743326, 0.86004645760743326, 0.82394502516453727, 0.85201316298877272, 0.85210994967092535, 0.84814169570267117, 0.84794812233836625, 0.86014324428958577, 0.84804490902051877, 0.82036391792489349, 0.8439798683701123, 0.86411149825783973, 0.84001161440185823, 0.85210994967092535, 0.85210994967092535, 0.85598141695702668, 0.79974835462640337, 0.84010840108401075, 0.82791327913279134, 0.8440766550522647, 0.86004645760743326, 0.72348044909020526, 0.86004645760743326, 0.83594657375145187, 0.8560782036391793, 0.8560782036391793, 0.84407665505226481, 0.8440766550522647, 0.86004645760743326, 0.80845915602013163, 0.86004645760743326, 0.85210994967092535, 0.86411149825783973, 0.85617499032133182, 0.85598141695702668, 0.83991482771970583, 0.84378629500580715, 0.84794812233836625, 0.82820363917924888, 0.85617499032133182, 0.86014324428958577, 0.86382113821138207, 0.86420828493999224, 0.85210994967092535, 0.85210994967092535, 0.83207510646535032, 0.8560782036391793, 0.85201316298877272, 0.86401471157568721, 0.72802942315137431, 0.85588463027487416, 0.8560782036391793, 0.8560782036391793, 0.84407665505226481, 0.86004645760743326, 0.8440766550522647, 0.81600851722802936, 0.85598141695702668, 0.86004645760743326, 0.80400696864111509, 0.84388308168795978, 0.84388308168795978, 0.83207510646535032, 0.85220673635307786, 0.84814169570267139, 0.86004645760743326, 0.8398180410375532, 0.86004645760743326, 0.82413859852884241, 0.85201316298877272, 0.84417344173441722, 0.8439798683701123, 0.76403406891211778, 0.82810685249709637, 0.8519163763066202, 0.86004645760743326, 0.85210994967092535, 0.85598141695702668, 0.86004645760743326, 0.71999612853271389, 0.8440766550522647, 0.85220673635307775, 0.86004645760743326, 0.83594657375145165, 0.85220673635307786, 0.86004645760743326, 0.85201316298877272, 0.86014324428958577, 0.86014324428958577, 0.74816105303910196, 0.86004645760743326, 0.83614014711575679, 0.86004645760743326, 0.85617499032133182, 0.84417344173441722, 0.8519163763066202, 0.86807975222609368, 0.85617499032133182, 0.84794812233836625, 0.8482384823848238, 0.83604336043360428, 0.8560782036391793, 0.82413859852884241, 0.86401471157568721, 0.85210994967092535, 0.83623693379790931, 0.85598141695702668, 0.85210994967092535, 0.85598141695702668, 0.87204800619434764, 0.8560782036391793, 0.82007355787843583, 0.82413859852884241, 0.83594657375145187, 0.84378629500580715, 0.8560782036391793, 0.86004645760743326, 0.82791327913279122, 0.85220673635307786, 0.86004645760743326, 0.74361207897793269, 0.84775454897406111, 0.8519163763066202, 0.84010840108401086, 0.85598141695702668, 0.86004645760743326, 0.79616724738675959, 0.85210994967092535, 0.84010840108401075, 0.83991482771970583, 0.84407665505226481, 0.83207510646535032, 0.86004645760743326, 0.86004645760743326]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'gini', 'max_depth': 19, 'max_features': 3, 'n_estimators': 15, 'normalize': 1, 'scale': 0}\n",
      "{'max_depth': 1, 'max_features': 4, 'n_estimators': 10, 'criterion': 'gini', 'verbose': 0}\n",
      "[0.84804490902051877, 0.85598141695702668, 0.8324622531939605, 0.83614014711575679, 0.84804490902051877, 0.86411149825783973, 0.86807975222609368, 0.83614014711575679, 0.85201316298877272, 0.80023228803716606, 0.66008517228029417, 0.86004645760743326, 0.84407665505226481, 0.85201316298877272, 0.80816879597367397, 0.73596593108788222, 0.86004645760743326, 0.84010840108401075, 0.81997677119628332, 0.84001161440185823, 0.84417344173441722, 0.85588463027487416, 0.84020518776616326, 0.83604336043360439, 0.86004645760743326, 0.8560782036391793, 0.85210994967092535, 0.83604336043360428, 0.80400696864111509, 0.8560782036391793, 0.84427022841656985, 0.84407665505226481, 0.86004645760743326, 0.86401471157568721, 0.86807975222609368, 0.85994967092528063, 0.85994967092528063, 0.8560782036391793, 0.84001161440185834, 0.86004645760743326, 0.86004645760743326, 0.85220673635307775, 0.85220673635307786, 0.84417344173441722, 0.86798296554394117, 0.84794812233836625, 0.8560782036391793, 0.86411149825783973, 0.75193573364305077, 0.85598141695702668, 0.8519163763066202, 0.86004645760743326, 0.8560782036391793, 0.73238482384823855, 0.86004645760743326, 0.8560782036391793, 0.83614014711575679, 0.86004645760743326, 0.82433217189314745, 0.85617499032133182, 0.84010840108401075, 0.84804490902051877, 0.84814169570267117, 0.8560782036391793, 0.8440766550522647, 0.86401471157568721, 0.85598141695702668, 0.8560782036391793, 0.8560782036391793, 0.84001161440185823, 0.86004645760743326, 0.86004645760743326, 0.84804490902051877, 0.84814169570267117, 0.78010065814943863, 0.688056523422377, 0.86004645760743326, 0.85598141695702668, 0.85627177700348434, 0.85201316298877272, 0.79974835462640337, 0.86014324428958577, 0.85201316298877272, 0.86004645760743326, 0.86401471157568721, 0.83991482771970583, 0.86401471157568721, 0.85210994967092535, 0.81591173054587696, 0.86004645760743326, 0.83991482771970583, 0.85201316298877272, 0.82007355787843583, 0.86401471157568721, 0.86004645760743326, 0.86004645760743326, 0.84388308168795978, 0.84794812233836625, 0.86004645760743326, 0.748354626403407, 0.84794812233836625, 0.81949283778552073, 0.85994967092528063, 0.85598141695702668, 0.84804490902051877, 0.84804490902051877, 0.8082655826558266, 0.85617499032133182, 0.83594657375145187, 0.86004645760743326, 0.87601626016260159, 0.83614014711575679, 0.83217189314750284, 0.85210994967092535, 0.83614014711575679, 0.86391792489353458, 0.85598141695702668, 0.85617499032133182, 0.8440766550522647, 0.86004645760743326, 0.86004645760743326, 0.76829268292682917, 0.85598141695702668, 0.80807200929152145, 0.82820363917924888, 0.85598141695702668, 0.86004645760743326, 0.86411149825783973, 0.84020518776616326, 0.84417344173441722, 0.84020518776616326, 0.84814169570267139, 0.8560782036391793, 0.85220673635307786, 0.85201316298877272, 0.86014324428958577, 0.86411149825783973, 0.84417344173441744, 0.84010840108401075, 0.87185443283004249, 0.84407665505226481, 0.86411149825783973, 0.84804490902051877, 0.85994967092528063, 0.84804490902051877, 0.86004645760743326, 0.86004645760743326, 0.8560782036391793, 0.85617499032133182, 0.71612466124661245, 0.8283004258614014, 0.85598141695702668, 0.84407665505226481, 0.85181958962446769, 0.84417344173441722, 0.84794812233836625, 0.85994967092528063, 0.85210994967092535, 0.84775454897406111, 0.85210994967092535, 0.8560782036391793, 0.86411149825783973, 0.8560782036391793, 0.84388308168795978, 0.86004645760743326, 0.85201316298877272, 0.86004645760743326, 0.86004645760743326, 0.82820363917924888, 0.85994967092528063, 0.68428184281842819, 0.79181184668989546, 0.85617499032133182, 0.86401471157568721, 0.86004645760743326, 0.76006581494386383, 0.86411149825783973, 0.8560782036391793, 0.85181958962446769, 0.84417344173441744, 0.86807975222609368, 0.84814169570267139, 0.8681765389082462, 0.84001161440185834, 0.85210994967092535, 0.86014324428958577, 0.8560782036391793, 0.86411149825783973, 0.85220673635307775, 0.83604336043360439, 0.85617499032133182, 0.85210994967092535, 0.84804490902051877, 0.84407665505226481, 0.86401471157568721, 0.85627177700348434, 0.83614014711575679, 0.85598141695702668, 0.86420828493999224, 0.85210994967092535, 0.86420828493999224, 0.8439798683701123, 0.85598141695702668, 0.83584978706929924, 0.86004645760743326, 0.86788617886178854, 0.84407665505226481, 0.85598141695702668, 0.86004645760743326, 0.80836236933797911, 0.85994967092528063, 0.86004645760743326, 0.82404181184668979, 0.86411149825783973, 0.86401471157568721, 0.85598141695702668, 0.86401471157568721, 0.8439798683701123, 0.84804490902051877, 0.85201316298877272, 0.84804490902051877, 0.84407665505226481, 0.86401471157568721, 0.84804490902051877, 0.82384823848238486, 0.84823848238482391, 0.8560782036391793, 0.85201316298877272, 0.86004645760743326, 0.7683894696089818, 0.8560782036391793, 0.8560782036391793, 0.85230352303523027, 0.8439798683701123, 0.85210994967092535, 0.84407665505226481, 0.84407665505226481, 0.82810685249709637, 0.8560782036391793, 0.84417344173441722, 0.84427022841656985, 0.8439798683701123, 0.85210994967092535, 0.83217189314750284, 0.86391792489353458, 0.81987998451413091, 0.86798296554394117, 0.86807975222609368, 0.85210994967092535, 0.86004645760743326, 0.86411149825783973, 0.83207510646535032, 0.86004645760743326, 0.83594657375145187, 0.84823848238482391, 0.82365466511807972, 0.86004645760743326, 0.79161827332559032, 0.85210994967092535, 0.78745644599303122, 0.83217189314750284, 0.86004645760743326, 0.85210994967092535, 0.8560782036391793, 0.84765776229190859, 0.8519163763066202, 0.80052264808362372, 0.82394502516453727, 0.84814169570267117, 0.84804490902051877, 0.85210994967092535, 0.8319783197831977, 0.85617499032133182, 0.8560782036391793, 0.84010840108401075, 0.86401471157568721, 0.85201316298877272, 0.79558652729384427, 0.86401471157568721, 0.85598141695702668, 0.86411149825783973, 0.85598141695702668, 0.83633372048006194, 0.86024003097173829, 0.86004645760743326, 0.85210994967092535, 0.84388308168795978, 0.85201316298877272, 0.76480836236933791, 0.82423538521099493, 0.85598141695702668, 0.81639566395663954, 0.86004645760743326, 0.85220673635307775, 0.85210994967092535, 0.85617499032133182, 0.85598141695702668, 0.87611304684475411, 0.86798296554394117, 0.85220673635307786]\n",
      "saved state to results/tracker_test_RandomForestClassifier.pickle\n",
      "Default RandomForestClassifier result on CV:\n",
      "\n",
      "loss = 0.745983352691\n",
      "best_n_estimators = 11\n",
      "params = {'max_depth': 1, 'max_features': 4, 'n_estimators': 10, 'criterion': 'gini', 'verbose': 0}\n",
      "{'criterion': 'gini', 'max_depth': 16, 'max_features': 1, 'n_estimators': 11, 'normalize': 1, 'scale': 1}\n",
      "{'max_depth': 1, 'max_features': 4, 'n_estimators': 10, 'criterion': 'gini', 'verbose': 0}\n",
      "[0.85998756932491871, 0.85597150506789055, 0.86001147446930581, 0.85802734748517884, 0.84999521897112251, 0.84999521897112251, 0.85597150506789055, 0.85599541021227765, 0.86001147446930581, 0.8138984509466437, 0.86001147446930581, 0.86799579269458782, 0.86601166571046095, 0.85998756932491871, 0.83596289921591127, 0.80395391088162171, 0.84394721744119339, 0.85800344234079173, 0.85797953719640463, 0.83787531076687705, 0.86001147446930581, 0.86001147446930581, 0.86003537961369292, 0.85401128322815067, 0.83804264677758644, 0.86001147446930581, 0.78193727290112836, 0.86001147446930581, 0.85599541021227765, 0.83799483648881246, 0.85599541021227765, 0.83598680436029837, 0.85599541021227765, 0.79807324536240198, 0.85195544081086261, 0.84997131382673563, 0.84602696500286856, 0.86001147446930581, 0.86393191814878556, 0.8520271562440237, 0.85800344234079173, 0.83794702620003825, 0.86199560145343279, 0.84593134442532036, 0.83603461464907236, 0.85398737808376357, 0.75196022183973987, 0.86001147446930581, 0.85800344234079162, 0.85998756932491871, 0.86001147446930581, 0.84189137502390521, 0.85599541021227765, 0.85594759992350367, 0.86001147446930581, 0.84595524956970747, 0.85599541021227765, 0.85391566265060226, 0.80796997513864977, 0.86199560145343279, 0.84994740868234853, 0.86395582329317266, 0.86001147446930581, 0.85396347293937647, 0.84590743928093326, 0.85398737808376357, 0.85800344234079173, 0.85795563205201775, 0.85996366418053161, 0.86001147446930581, 0.75399215911264106, 0.83988334289539113, 0.85393956779498958, 0.85393956779498958, 0.84997131382673563, 0.85599541021227754, 0.85601931535666476, 0.84801109198699554, 0.8620195065978199, 0.7959695926563396, 0.85996366418053161, 0.85797953719640463, 0.84997131382673541, 0.86001147446930581, 0.85398737808376357, 0.86199560145343279, 0.84607477529164266, 0.86199560145343279, 0.86001147446930581, 0.86001147446930581, 0.85797953719640463, 0.84590743928093326, 0.85599541021227765, 0.79195352839931166, 0.81803404092560728, 0.85599541021227765, 0.79192962325492433, 0.85599541021227765, 0.85398737808376357, 0.85800344234079173, 0.85599541021227765, 0.84798718684260843, 0.86393191814878556, 0.78612067316886591, 0.86199560145343279, 0.85800344234079173, 0.82589883342895387, 0.85597150506789055, 0.86001147446930581, 0.84801109198699554, 0.86402753872633387, 0.85599541021227765, 0.85797953719640463, 0.86204341174220689, 0.85800344234079173, 0.85398737808376357, 0.85800344234079173, 0.86001147446930581, 0.83601070950468548, 0.85797953719640463, 0.85998756932491871, 0.86001147446930581, 0.86598776056607374, 0.86197169630904569, 0.84997131382673541, 0.85998756932491871, 0.86003537961369292, 0.8238668961560528, 0.85998756932491871, 0.84593134442532048, 0.84196309045706641, 0.84999521897112251, 0.84999521897112251, 0.86598776056607385, 0.84007458405048763, 0.85797953719640463, 0.85800344234079173, 0.85800344234079173, 0.86001147446930581, 0.86001147446930581, 0.86001147446930581, 0.8600114744693057, 0.83381143622107479, 0.86001147446930581, 0.84590743928093326, 0.86201950659781978, 0.84997131382673563, 0.83993115318416522, 0.7859533371581563, 0.84798718684260843, 0.8620195065978199, 0.82597054886211518, 0.85800344234079173, 0.79190571811053745, 0.85398737808376357, 0.85601931535666476, 0.86001147446930581, 0.86199560145343279, 0.79996175176898066, 0.86001147446930581, 0.85403518837253778, 0.81803404092560716, 0.82998661311914324, 0.86001147446930581, 0.85195544081086261, 0.86001147446930581, 0.83596289921591127, 0.84397112258558049, 0.85594759992350367, 0.86001147446930581, 0.78193727290112836, 0.83194683495888311, 0.83797093134442535, 0.82195448460508702, 0.85800344234079173, 0.85587588449034235, 0.84201090074584062, 0.8620195065978199, 0.84392331229680639, 0.85597150506789055, 0.8600114744693057, 0.84193918531267931, 0.85797953719640463, 0.86001147446930581, 0.84798718684260843, 0.84193918531267931, 0.85393956779498958, 0.86001147446930581, 0.8340265825205585, 0.84798718684260843, 0.86395582329317266, 0.86400363358194687, 0.75972939376553839, 0.84394721744119339, 0.86400363358194687, 0.84012239433926184, 0.85998756932491871, 0.8519315356664755, 0.84798718684260843, 0.85998756932491871, 0.81992254733218584, 0.85800344234079173, 0.86001147446930581, 0.8439950277299676, 0.86001147446930581, 0.85597150506789055, 0.85197934595524949, 0.84595524956970747, 0.84805890227576974, 0.8240342321667623, 0.86001147446930581, 0.8519076305220884, 0.8520271562440237, 0.85996366418053161, 0.79819277108433739, 0.85396347293937647, 0.86001147446930581, 0.78803308471983169, 0.85599541021227765, 0.86199560145343279, 0.85800344234079173, 0.85592369477911634, 0.85597150506789055, 0.8520271562440237, 0.80206540447504304, 0.85398737808376357, 0.86598776056607385, 0.85795563205201752, 0.85998756932491871, 0.85800344234079173, 0.85797953719640463, 0.84401893287435448, 0.85393956779498958, 0.83395486708739719, 0.85589978963472946, 0.83596289921591127, 0.84997131382673563, 0.83385924650984899, 0.85797953719640463, 0.85195544081086261, 0.86001147446930581, 0.83799483648881246, 0.85398737808376357, 0.85599541021227765, 0.8439950277299676, 0.78827213616370251, 0.84997131382673563, 0.87002772996748901, 0.7778973034997132, 0.85599541021227765, 0.83598680436029837, 0.86601166571046095, 0.8519315356664755, 0.84597915471409435, 0.86003537961369292, 0.86001147446930581, 0.85597150506789055, 0.86197169630904569, 0.85800344234079173, 0.85797953719640463, 0.86001147446930581, 0.85001912411550962, 0.85398737808376357, 0.85797953719640463, 0.86194779116465858, 0.86001147446930581, 0.81987473704341174, 0.84997131382673563, 0.85599541021227765, 0.8600114744693057, 0.85200325109963659, 0.86001147446930581, 0.84588353413654627, 0.85001912411550962, 0.85998756932491871, 0.84997131382673541, 0.85800344234079173, 0.85599541021227765, 0.83407439280933249, 0.74985656913367749, 0.8439950277299676, 0.85996366418053161, 0.86001147446930581, 0.80189806846433365, 0.85599541021227765, 0.85802734748517884, 0.84401893287435448, 0.86400363358194687, 0.85200325109963659, 0.85998756932491871, 0.85797953719640463, 0.78607286288009171, 0.86001147446930581, 0.85800344234079173, 0.85599541021227765, 0.85802734748517884, 0.84997131382673541, 0.86001147446930581, 0.82998661311914335, 0.85398737808376379]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'XYCDataset' object has no attribute 'get_label'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-edc3882e5a3b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m                                                   \u001b[0mdefault_cv_result\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'params'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                                                   \u001b[0mdefault_cv_result\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'best_n_estimators'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m                                                   custom_metric = {'roc_auc': roc_auc_score})\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mtrackers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdefault_test_result\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/py3/lib/python3.6/site-packages/modelgym-0.1.2.1-py3.6.egg/modelgym/trainer.py\u001b[0m in \u001b[0;36mfit_eval\u001b[0;34m(self, model, dtrain, dtest, params, n_estimators, custom_metric)\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_dtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# TODO: why 2 args?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmetric_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric_func\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcustom_metric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m                 \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetric_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_dtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# TODO weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m                 \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmetric_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'XYCDataset' object has no attribute 'get_label'"
     ]
    }
   ],
   "source": [
    "for model_id, model_class in CANDIDATES.items():\n",
    "    model = model_class(TASK_CLASSIFICATION)\n",
    "    print (\"~\"*20, model.get_name(), \"~\"*20)\n",
    "    trackers[model_id] = tracker_factory(model_name=model.get_name())\n",
    "    if LOAD_CACHE:\n",
    "        default_cv_result[model_id], default_test_result[model_id], tuned_cv_result[model_id], tuned_test_result[model_id], trials[model_id] = \\\n",
    "            trackers[model_id].load_state(as_list=True)\n",
    "    \n",
    "    \n",
    "    if default_cv_result[model_id] is None:\n",
    "        default_cv_result[model_id] = trainer.crossval_fit_eval(model, cv_pairs)\n",
    "        trackers[model_id].save_state(default_cv=default_cv_result[model_id])\n",
    "    trainer.print_result(default_cv_result[model_id], 'Default {} result on CV'.format(model.get_name()))\n",
    "\n",
    "    if default_test_result[model_id] is None:\n",
    "        default_test_result[model_id] = trainer.fit_eval(model, dtrain, dtest,\n",
    "                                                  default_cv_result[model_id]['params'],\n",
    "                                                  default_cv_result[model_id]['best_n_estimators'],\n",
    "                                                  custom_metric = {'roc_auc': roc_auc_score})\n",
    "        trackers[model_id].save_state(default_test=default_test_result[model_id])\n",
    "\n",
    "    trainer.print_result(default_test_result[model_id], 'Default {} result on TEST'.format(model.get_name()), extra_keys=['roc_auc'])\n",
    "\n",
    "        \n",
    "    if tuned_cv_result[model_id] is None:\n",
    "        print('Hyperopt iterations:\\n\\n')\n",
    "        tuned_cv_result[model_id] = trainer.crossval_optimize_params(model, cv_pairs,  algo_name=OPTIMIZER, \n",
    "                                                           trials=trials[model_id], tracker=trackers[model_id])\n",
    "        trackers[model_id].save_state(tuned_cv=tuned_cv_result[model_id])\n",
    "    trainer.print_result(tuned_cv_result[model_id], 'Tuned {} result on cv'.format(model.get_name()))\n",
    "\n",
    "    if tuned_test_result[model_id] is None:\n",
    "        tuned_test_result[model_id] = trainer.fit_eval(model, dtrain, dtest,\n",
    "                                            tuned_cv_result[model_id]['params'],\n",
    "                                            tuned_cv_result[model_id]['best_n_estimators'],\n",
    "                                            custom_metric = {'roc_auc': roc_auc_score})\n",
    "        trackers[model_id].save_state(tuned_test=tuned_test_result[model_id])\n",
    "    trainer.print_result(tuned_test_result[model_id], 'Tuned {} result on test'.format(model.get_name()), extra_keys=['roc_auc'])\n",
    "\n",
    "    trackers[model_id].save_state(default_cv=default_cv_result[model_id], default_test=default_test_result[model_id], \n",
    "                               tuned_cv=tuned_cv_result[model_id], tuned_test=tuned_test_result[model_id], trials=trials[model_id])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "metric, mes_min = 'roc_auc', False\n",
    "full_results = {}\n",
    "for i in CANDIDATES.keys():\n",
    "    if i in trackers:\n",
    "        tracker = trackers[i]\n",
    "    else:\n",
    "        tracker = tracker_factory(model_name=i)\n",
    "        tracker.load_state()\n",
    "    full_results.update({i:{'tuned': tracker.state['tuned_test'], 'default': tracker.state['default_test']}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_metric_results(full_results, index, metric, is_min_better=True):\n",
    "    test_results_list = []\n",
    "    for i in index:\n",
    "        test_results_list.append([full_results[i]['default'][metric], full_results[i]['tuned'][metric]])\n",
    "        \n",
    "    test_results = np.array(test_results_list)\n",
    "    if is_min_better:\n",
    "        baseline = test_results.min()\n",
    "    else:\n",
    "        baseline = test_results.max()\n",
    "    diff = 100 * test_results / baseline - 100\n",
    "    test_results_formatted = [['{:.6f} ({:+.2f}%)'.format(test_results[i, j], diff[i, j]) for j in range(2)] for i in range(len(index))]\n",
    "\n",
    "    print (pd.DataFrame(test_results_formatted, columns=['default', 'tuned'], index=index))\n",
    "    \n",
    "    full_names = [\" \".join(i) for i in itertools.product(index, ['default', 'tuned'])]\n",
    "\n",
    "    named_results = zip(full_names, test_results.flatten())\n",
    "\n",
    "    sorted_results = sorted(named_results, key=lambda x: x[1], reverse=not is_min_better)\n",
    "    xticks = ['%s\\n%.5f' % (name, loss) for name, loss in sorted_results]\n",
    "\n",
    "    pyplot.figure(figsize=(20, 7))\n",
    "    pyplot.scatter(range(len(full_names)), list(zip(*sorted_results))[1], s=150)\n",
    "    pyplot.xticks(range(len(full_names)), xticks, fontsize=15)\n",
    "    pyplot.yticks(fontsize=12)\n",
    "    pyplot.title('Comparison', fontsize=20)\n",
    "    pyplot.ylabel(metric, fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%pylab inline --no-import-all\n",
    "metric, is_min_better = 'roc_auc', False\n",
    "plot_metric_results(full_results, CANDIDATES.keys(), metric, is_min_better=is_min_better)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
